# ğŸ—ï¸ å¤©åº­ç³»ç»ŸæŠ€æœ¯æ¶æ„è®¾è®¡

## ğŸ¯ æ¶æ„è®¾è®¡åŸåˆ™

### æ ¸å¿ƒè®¾è®¡ç†å¿µ
åŸºäº"è¨€å‡ºæ³•éš"çš„äº§å“æ„¿æ™¯ï¼ŒæŠ€æœ¯æ¶æ„éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **æ¸è¿›å¼æ¼”è¿›**: æ”¯æŒä»ç®€å•åˆ°å¤æ‚çš„å¹³æ»‘å‡çº§
2. **æ¨¡å—åŒ–è®¾è®¡**: é«˜å†…èšä½è€¦åˆï¼Œä¾¿äºç‹¬ç«‹å¼€å‘å’Œæµ‹è¯•
3. **AIä¼˜å…ˆ**: æ‰€æœ‰ç»„ä»¶éƒ½ä¸ºAIé›†æˆå’Œåä½œä¼˜åŒ–
4. **æ€§èƒ½å¯¼å‘**: ä¼˜åŒ–å“åº”æ—¶é—´ï¼Œç¡®ä¿ç”¨æˆ·ä½“éªŒ
5. **å¯æ‰©å±•æ€§**: æ”¯æŒä»å•ç”¨æˆ·åˆ°ä¼ä¸šçº§çš„è§„æ¨¡æ‰©å±•

### æŠ€æœ¯é€‰å‹ç­–ç•¥
- **æˆç†Ÿä¼˜å…ˆ**: é€‰æ‹©ç»è¿‡éªŒè¯çš„æŠ€æœ¯æ ˆ
- **AIå‹å¥½**: ä¼˜å…ˆé€‰æ‹©AIç”Ÿæ€æ”¯æŒè‰¯å¥½çš„æŠ€æœ¯
- **å¼€å‘æ•ˆç‡**: å¹³è¡¡å¼€å‘é€Ÿåº¦å’Œç³»ç»Ÿæ€§èƒ½
- **æˆæœ¬æ§åˆ¶**: è€ƒè™‘éƒ¨ç½²å’Œè¿ç»´æˆæœ¬

---

## ğŸš€ Stage 0: æ™ºèƒ½å·¥ä½œæµå¼•æ“æ¶æ„

### ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

```mermaid
graph TB
    subgraph "ğŸŒ å‰ç«¯å±‚"
        UI[React + TypeScript]
        UI --> WS[WebSocketå®¢æˆ·ç«¯]
    end
    
    subgraph "ğŸ”Œ APIå±‚"
        API[FastAPIæœåŠ¡å™¨]
        AUTH[è®¤è¯ä¸­é—´ä»¶]
        LIMIT[é™æµä¸­é—´ä»¶]
    end
    
    subgraph "ğŸ§  AIæœåŠ¡å±‚"
        NLU[éœ€æ±‚ç†è§£å¼•æ“]
        PLAN[é¡¹ç›®è§„åˆ’ç”Ÿæˆå™¨]
        ADJ[äº¤äº’å¼è°ƒæ•´å™¨]
        OUT[è§„åˆ’è¾“å‡ºå™¨]
    end
    
    subgraph "ğŸ¤– å¤–éƒ¨AI"
        CLAUDE[Claude API]
        PROMPTX[PromptX MCP]
    end
    
    subgraph "ğŸ’¾ æ•°æ®å±‚"
        DB[(SQLite)]
        CACHE[Redisç¼“å­˜]
        FILES[æ–‡ä»¶å­˜å‚¨]
    end
    
    UI --> API
    API --> AUTH
    AUTH --> LIMIT
    LIMIT --> NLU
    LIMIT --> PLAN
    LIMIT --> ADJ
    LIMIT --> OUT
    
    NLU --> CLAUDE
    PLAN --> CLAUDE
    ADJ --> CLAUDE
    OUT --> PROMPTX
    
    NLU --> DB
    PLAN --> DB
    ADJ --> CACHE
    OUT --> FILES
    
    style NLU fill:#ff6b6b,color:#fff
    style PLAN fill:#4ecdc4,color:#fff
    style ADJ fill:#45b7d1,color:#fff
    style OUT fill:#96ceb4,color:#fff
```

### æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### 1. éœ€æ±‚ç†è§£å¼•æ“ (NLU Engine)

**èŒè´£**: è§£æç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œæå–ç»“æ„åŒ–éœ€æ±‚ä¿¡æ¯

**æŠ€æœ¯æ ˆ**:
```yaml
è¯­è¨€: Python 3.11+
æ¡†æ¶: FastAPI + Pydantic
AIé›†æˆ: Claude API (Sonnet-3.5)
NLPå¤„ç†: spaCy + transformers
æ•°æ®éªŒè¯: Pydantic models
```

**æ ¸å¿ƒç®—æ³•**:
```python
class RequirementParser:
    def __init__(self):
        self.claude_client = ClaudeClient()
        self.nlp_processor = spacy.load("zh_core_web_sm")
        
    async def parse_requirement(self, user_input: str) -> RequirementModel:
        # 1. é¢„å¤„ç†æ–‡æœ¬
        processed_text = self.preprocess_text(user_input)
        
        # 2. å®ä½“è¯†åˆ«
        entities = self.extract_entities(processed_text)
        
        # 3. æ„å›¾åˆ†ç±»
        intent = await self.classify_intent(processed_text)
        
        # 4. ç»“æ„åŒ–æå–
        structured_req = await self.extract_structure(
            processed_text, entities, intent
        )
        
        return RequirementModel(**structured_req)
```

**æ•°æ®æ¨¡å‹**:
```python
class RequirementModel(BaseModel):
    project_type: ProjectType
    target_users: List[UserGroup]
    core_features: List[Feature]
    technical_constraints: List[Constraint]
    business_model: BusinessModel
    priority_level: PriorityLevel
    estimated_complexity: ComplexityLevel
```

#### 2. é¡¹ç›®è§„åˆ’ç”Ÿæˆå™¨ (Project Planner)

**èŒè´£**: åŸºäºç†è§£çš„éœ€æ±‚ç”Ÿæˆå®Œæ•´é¡¹ç›®è§„åˆ’

**æŠ€æœ¯æ ˆ**:
```yaml
è¯­è¨€: Python 3.11+
æ¨¡æ¿å¼•æ“: Jinja2
å›¾è¡¨ç”Ÿæˆ: matplotlib + plotly
æ–‡æ¡£ç”Ÿæˆ: reportlab + markdown
çŸ¥è¯†åº“: é¡¹ç›®æ¨¡æ¿æ•°æ®åº“
```

**æ ¸å¿ƒæ¶æ„**:
```python
class ProjectPlanner:
    def __init__(self):
        self.template_db = TemplateDatabase()
        self.cost_calculator = CostCalculator()
        self.timeline_estimator = TimelineEstimator()
        
    async def generate_plan(self, requirement: RequirementModel) -> ProjectPlan:
        # 1. é€‰æ‹©é¡¹ç›®æ¨¡æ¿
        template = self.select_template(requirement.project_type)
        
        # 2. ç”Ÿæˆç”¨æˆ·æ—…ç¨‹
        user_journey = await self.generate_user_journey(requirement)
        
        # 3. è®¾è®¡æŠ€æœ¯æ¶æ„
        tech_architecture = await self.design_architecture(requirement)
        
        # 4. åˆ†è§£åŠŸèƒ½æ¨¡å—
        modules = await self.decompose_modules(requirement)
        
        # 5. åˆ¶å®šå¼€å‘è®¡åˆ’
        timeline = self.estimate_timeline(modules)
        
        # 6. è®¡ç®—æˆæœ¬é¢„ç®—
        budget = self.calculate_budget(modules, timeline)
        
        return ProjectPlan(
            user_journey=user_journey,
            architecture=tech_architecture,
            modules=modules,
            timeline=timeline,
            budget=budget
        )
```

#### 3. äº¤äº’å¼è°ƒæ•´å™¨ (Interactive Adjuster)

**èŒè´£**: å¤„ç†ç”¨æˆ·åé¦ˆï¼Œæ™ºèƒ½è°ƒæ•´é¡¹ç›®è§„åˆ’

**æŠ€æœ¯æ ˆ**:
```yaml
è¯­è¨€: Python 3.11+
å®æ—¶é€šä¿¡: WebSocket + Redis
çŠ¶æ€ç®¡ç†: Redis + JSON
ç‰ˆæœ¬æ§åˆ¶: Git-like diffç®—æ³•
```

**è°ƒæ•´ç­–ç•¥**:
```python
class InteractiveAdjuster:
    def __init__(self):
        self.feedback_analyzer = FeedbackAnalyzer()
        self.plan_modifier = PlanModifier()
        self.version_manager = VersionManager()
        
    async def process_feedback(
        self, 
        plan: ProjectPlan, 
        feedback: UserFeedback
    ) -> AdjustedPlan:
        # 1. åˆ†æåé¦ˆæ„å›¾
        intent = await self.feedback_analyzer.analyze(feedback)
        
        # 2. ç”Ÿæˆè°ƒæ•´æ–¹æ¡ˆ
        adjustments = await self.plan_modifier.generate_adjustments(
            plan, intent
        )
        
        # 3. éªŒè¯è°ƒæ•´ä¸€è‡´æ€§
        validated_plan = self.validate_consistency(plan, adjustments)
        
        # 4. ä¿å­˜ç‰ˆæœ¬å†å²
        self.version_manager.save_version(plan, validated_plan)
        
        return validated_plan
```

#### 4. è§„åˆ’è¾“å‡ºå™¨ (Plan Exporter)

**èŒè´£**: å°†æœ€ç»ˆè§„åˆ’è¾“å‡ºä¸ºå„ç§æ ¼å¼çš„æ–‡æ¡£

**æŠ€æœ¯æ ˆ**:
```yaml
è¯­è¨€: Python 3.11+
PDFç”Ÿæˆ: reportlab + weasyprint
æ–‡æ¡£æ¨¡æ¿: Jinja2 + Markdown
å›¾è¡¨ç”Ÿæˆ: matplotlib + mermaid
äº‘å­˜å‚¨: æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ (Stage 0)
```

### æ•°æ®åº“è®¾è®¡

#### SQLite Schemaè®¾è®¡
```sql
-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- é¡¹ç›®è¡¨
CREATE TABLE projects (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    name VARCHAR(200) NOT NULL,
    description TEXT,
    project_type VARCHAR(50) NOT NULL,
    status VARCHAR(20) DEFAULT 'planning',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- éœ€æ±‚è¡¨
CREATE TABLE requirements (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_id INTEGER NOT NULL,
    raw_input TEXT NOT NULL,
    parsed_data JSON NOT NULL,
    confidence_score REAL NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (project_id) REFERENCES projects(id)
);

-- è§„åˆ’è¡¨
CREATE TABLE plans (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_id INTEGER NOT NULL,
    version INTEGER NOT NULL DEFAULT 1,
    plan_data JSON NOT NULL,
    is_current BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (project_id) REFERENCES projects(id)
);

-- åé¦ˆè¡¨
CREATE TABLE feedbacks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    plan_id INTEGER NOT NULL,
    feedback_text TEXT NOT NULL,
    feedback_type VARCHAR(20) NOT NULL,
    processed BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (plan_id) REFERENCES plans(id)
);
```

### APIè®¾è®¡

#### RESTful APIç«¯ç‚¹
```yaml
åŸºç¡€è·¯å¾„: /api/v1

è®¤è¯ç«¯ç‚¹:
  POST /auth/login     # ç”¨æˆ·ç™»å½•
  POST /auth/register  # ç”¨æˆ·æ³¨å†Œ
  POST /auth/logout    # ç”¨æˆ·ç™»å‡º

é¡¹ç›®ç®¡ç†:
  GET  /projects       # è·å–é¡¹ç›®åˆ—è¡¨
  POST /projects       # åˆ›å»ºæ–°é¡¹ç›®
  GET  /projects/{id}  # è·å–é¡¹ç›®è¯¦æƒ…
  PUT  /projects/{id}  # æ›´æ–°é¡¹ç›®ä¿¡æ¯
  DELETE /projects/{id} # åˆ é™¤é¡¹ç›®

éœ€æ±‚å¤„ç†:
  POST /projects/{id}/requirements  # æäº¤éœ€æ±‚
  GET  /projects/{id}/requirements  # è·å–éœ€æ±‚å†å²

è§„åˆ’ç”Ÿæˆ:
  POST /projects/{id}/plan          # ç”Ÿæˆè§„åˆ’
  GET  /projects/{id}/plan          # è·å–å½“å‰è§„åˆ’
  GET  /projects/{id}/plan/versions # è·å–å†å²ç‰ˆæœ¬

äº¤äº’è°ƒæ•´:
  POST /projects/{id}/feedback      # æäº¤åé¦ˆ
  POST /projects/{id}/adjust        # æ‰§è¡Œè°ƒæ•´

æ–‡æ¡£å¯¼å‡º:
  GET  /projects/{id}/export/pdf    # å¯¼å‡ºPDF
  GET  /projects/{id}/export/docx   # å¯¼å‡ºWord
  GET  /projects/{id}/export/md     # å¯¼å‡ºMarkdown
```

#### WebSocketäº‹ä»¶
```yaml
è¿æ¥: /ws/projects/{project_id}

å®¢æˆ·ç«¯äº‹ä»¶:
  requirement_submit   # æäº¤éœ€æ±‚
  feedback_submit      # æäº¤åé¦ˆ
  plan_adjust_request  # è¯·æ±‚è°ƒæ•´

æœåŠ¡ç«¯äº‹ä»¶:
  requirement_processing  # éœ€æ±‚å¤„ç†ä¸­
  requirement_completed   # éœ€æ±‚å¤„ç†å®Œæˆ
  plan_generating        # è§„åˆ’ç”Ÿæˆä¸­
  plan_completed         # è§„åˆ’ç”Ÿæˆå®Œæˆ
  adjustment_processing  # è°ƒæ•´å¤„ç†ä¸­
  adjustment_completed   # è°ƒæ•´å®Œæˆ
  error_occurred         # é”™è¯¯å‘ç”Ÿ
```

---

## ğŸ”„ Stage 1: å¤šçª—å£å¹¶å‘æ‰§è¡Œæ¶æ„

### æ¶æ„å‡çº§æ¦‚è§ˆ

```mermaid
graph TB
    subgraph "ğŸ‘¥ ç”¨æˆ·å±‚"
        USER[ç”¨æˆ·ç•Œé¢]
        MONITOR[å¹¶å‘ç›‘æ§é¢æ¿]
    end
    
    subgraph "ğŸ›ï¸ åè°ƒå±‚"
        ORCHESTRATOR[ä¸»åè°ƒå™¨]
        SCHEDULER[ä»»åŠ¡è°ƒåº¦å™¨]
        RESOLVER[å†²çªè§£å†³å™¨]
    end
    
    subgraph "ğŸªŸ å¤šçª—å£å±‚"
        W1[å‰ç«¯çª—å£]
        W2[åç«¯çª—å£]
        W3[æµ‹è¯•çª—å£]
        W4[æ–‡æ¡£çª—å£]
    end
    
    subgraph "ğŸ’¬ é€šä¿¡å±‚"
        REDIS[Redis Pub/Sub]
        WS[WebSocket]
        MQ[æ¶ˆæ¯é˜Ÿåˆ—]
    end
    
    subgraph "ğŸ”„ çŠ¶æ€å±‚"
        STATE[çŠ¶æ€ç®¡ç†å™¨]
        VERSION[ç‰ˆæœ¬æ§åˆ¶]
        LOCK[åˆ†å¸ƒå¼é”]
    end
    
    subgraph "ğŸ¤– AIé›†æˆ"
        CLAUDE[Claude Code API]
        PROMPTX[PromptX MCP]
    end
    
    USER --> ORCHESTRATOR
    MONITOR --> ORCHESTRATOR
    
    ORCHESTRATOR --> SCHEDULER
    ORCHESTRATOR --> RESOLVER
    
    SCHEDULER --> W1
    SCHEDULER --> W2
    SCHEDULER --> W3
    SCHEDULER --> W4
    
    W1 --> REDIS
    W2 --> REDIS
    W3 --> REDIS
    W4 --> REDIS
    
    REDIS --> STATE
    STATE --> VERSION
    STATE --> LOCK
    
    W1 --> CLAUDE
    W2 --> CLAUDE
    W3 --> CLAUDE
    W4 --> PROMPTX
    
    style ORCHESTRATOR fill:#ff6b6b,color:#fff
    style SCHEDULER fill:#4ecdc4,color:#fff
    style RESOLVER fill:#45b7d1,color:#fff
    style STATE fill:#96ceb4,color:#fff
```

### æ–°å¢æ ¸å¿ƒç»„ä»¶

#### 1. ä¸»åè°ƒå™¨ (Main Orchestrator)

**èŒè´£**: ç»Ÿä¸€ç®¡ç†å’Œåè°ƒæ‰€æœ‰å¹¶å‘å¼€å‘çª—å£

**æŠ€æœ¯æ ˆ**:
```yaml
è¯­è¨€: Python 3.11+ (å¼‚æ­¥ç¼–ç¨‹)
è¿›ç¨‹ç®¡ç†: asyncio + multiprocessing
çª—å£ç®¡ç†: Claude Code APIå®¢æˆ·ç«¯
ç›‘æ§: prometheus_client
```

**æ ¸å¿ƒå®ç°**:
```python
class MainOrchestrator:
    def __init__(self):
        self.window_manager = WindowManager()
        self.task_scheduler = TaskScheduler()
        self.conflict_resolver = ConflictResolver()
        self.state_manager = StateManager()
        
    async def start_concurrent_development(self, project_plan: ProjectPlan):
        # 1. åˆ†æé¡¹ç›®è®¡åˆ’ï¼Œåˆ†è§£ä»»åŠ¡
        tasks = await self.decompose_tasks(project_plan)
        
        # 2. å¯åŠ¨å¤šä¸ªå¼€å‘çª—å£
        windows = await self.window_manager.create_windows(4)
        
        # 3. åˆ†é…ä»»åŠ¡åˆ°çª—å£
        task_assignments = await self.task_scheduler.assign_tasks(
            tasks, windows
        )
        
        # 4. å¯åŠ¨å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*[
            self.execute_window_tasks(window, assignments)
            for window, assignments in task_assignments.items()
        ])
        
        # 5. é›†æˆæ‰€æœ‰ç»“æœ
        integrated_project = await self.integrate_results(results)
        
        return integrated_project
```

#### 2. ä»»åŠ¡è°ƒåº¦å™¨ (Task Scheduler)

**èŒè´£**: æ™ºèƒ½åˆ†é…ä»»åŠ¡ç»™ä¸åŒçª—å£ï¼Œç®¡ç†ä¾èµ–å…³ç³»

**è°ƒåº¦ç®—æ³•**:
```python
class TaskScheduler:
    def __init__(self):
        self.dependency_analyzer = DependencyAnalyzer()
        self.load_balancer = LoadBalancer()
        
    async def assign_tasks(self, tasks: List[Task], windows: List[Window]):
        # 1. åˆ†æä»»åŠ¡ä¾èµ–å…³ç³»
        dependency_graph = self.dependency_analyzer.build_graph(tasks)
        
        # 2. æ‹“æ‰‘æ’åºç¡®å®šæ‰§è¡Œé¡ºåº
        execution_order = self.topological_sort(dependency_graph)
        
        # 3. æŒ‰çª—å£ä¸“ä¸šé¢†åŸŸåˆ†ç»„
        task_groups = {
            'frontend': [],
            'backend': [],
            'testing': [],
            'documentation': []
        }
        
        for task in execution_order:
            group = self.classify_task(task)
            task_groups[group].append(task)
        
        # 4. è´Ÿè½½å‡è¡¡åˆ†é…
        assignments = self.load_balancer.assign(task_groups, windows)
        
        return assignments
```

#### 3. å†²çªè§£å†³å™¨ (Conflict Resolver)

**èŒè´£**: æ£€æµ‹å’Œè‡ªåŠ¨è§£å†³å¤šçª—å£å¼€å‘ä¸­çš„å†²çª

**å†²çªæ£€æµ‹ç®—æ³•**:
```python
class ConflictResolver:
    def __init__(self):
        self.file_monitor = FileMonitor()
        self.api_monitor = APIMonitor()
        self.db_monitor = DatabaseMonitor()
        
    async def detect_conflicts(self, changes: List[Change]) -> List[Conflict]:
        conflicts = []
        
        # 1. æ–‡ä»¶çº§å†²çªæ£€æµ‹
        file_conflicts = await self.detect_file_conflicts(changes)
        conflicts.extend(file_conflicts)
        
        # 2. APIæ¥å£å†²çªæ£€æµ‹
        api_conflicts = await self.detect_api_conflicts(changes)
        conflicts.extend(api_conflicts)
        
        # 3. æ•°æ®åº“schemaå†²çªæ£€æµ‹
        db_conflicts = await self.detect_db_conflicts(changes)
        conflicts.extend(db_conflicts)
        
        return conflicts
    
    async def resolve_conflicts(self, conflicts: List[Conflict]) -> Resolution:
        resolutions = []
        
        for conflict in conflicts:
            if conflict.type == ConflictType.FILE_MERGE:
                resolution = await self.auto_merge_files(conflict)
            elif conflict.type == ConflictType.API_INTERFACE:
                resolution = await self.harmonize_api(conflict)
            elif conflict.type == ConflictType.DATABASE_SCHEMA:
                resolution = await self.merge_schema(conflict)
            else:
                resolution = await self.request_manual_resolution(conflict)
            
            resolutions.append(resolution)
        
        return Resolution(resolutions)
```

#### 4. çŠ¶æ€ç®¡ç†å™¨ (State Manager)

**èŒè´£**: ç»´æŠ¤æ‰€æœ‰çª—å£çš„ä¸€è‡´çŠ¶æ€ï¼Œæ”¯æŒå®æ—¶åŒæ­¥

**çŠ¶æ€åŒæ­¥æœºåˆ¶**:
```python
class StateManager:
    def __init__(self):
        self.redis_client = redis.Redis()
        self.websocket_manager = WebSocketManager()
        self.version_control = VersionControl()
        
    async def sync_state(self, window_id: str, state_change: StateChange):
        # 1. æ›´æ–°Redisä¸­çš„çŠ¶æ€
        await self.redis_client.hset(
            f"project:{state_change.project_id}:state",
            window_id,
            json.dumps(state_change.data)
        )
        
        # 2. å¹¿æ’­çŠ¶æ€å˜æ›´åˆ°å…¶ä»–çª—å£
        await self.websocket_manager.broadcast(
            f"project:{state_change.project_id}",
            {
                "type": "state_update",
                "window_id": window_id,
                "change": state_change.data
            }
        )
        
        # 3. è®°å½•ç‰ˆæœ¬å†å²
        await self.version_control.record_change(state_change)
        
    async def get_consistent_state(self, project_id: str) -> ProjectState:
        # ä»Redisè·å–æ‰€æœ‰çª—å£çš„æœ€æ–°çŠ¶æ€
        state_data = await self.redis_client.hgetall(
            f"project:{project_id}:state"
        )
        
        # åˆå¹¶ä¸ºä¸€è‡´çš„é¡¹ç›®çŠ¶æ€
        consistent_state = self.merge_window_states(state_data)
        
        return consistent_state
```

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 1. å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼
```python
# ä½¿ç”¨asyncioå®ç°é«˜å¹¶å‘
async def process_multiple_windows():
    tasks = [
        process_window(window_id) 
        for window_id in active_windows
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results
```

#### 2. è¿æ¥æ± ç®¡ç†
```python
# Redisè¿æ¥æ± 
redis_pool = redis.ConnectionPool(
    host='localhost',
    port=6379,
    max_connections=20
)

# Claude APIè¿æ¥æ± 
claude_session = aiohttp.ClientSession(
    connector=aiohttp.TCPConnector(limit=10)
)
```

#### 3. æ™ºèƒ½ç¼“å­˜ç­–ç•¥
```python
class SmartCache:
    def __init__(self):
        self.redis = redis.Redis()
        self.local_cache = {}
        
    async def get_cached_result(self, key: str, generator_func):
        # 1. æ£€æŸ¥æœ¬åœ°ç¼“å­˜
        if key in self.local_cache:
            return self.local_cache[key]
            
        # 2. æ£€æŸ¥Redisç¼“å­˜
        cached = await self.redis.get(key)
        if cached:
            result = json.loads(cached)
            self.local_cache[key] = result
            return result
            
        # 3. ç”Ÿæˆæ–°ç»“æœå¹¶ç¼“å­˜
        result = await generator_func()
        await self.redis.setex(key, 3600, json.dumps(result))
        self.local_cache[key] = result
        return result
```

---

## ğŸ“Š æŠ€æœ¯é€‰å‹è¯¦ç»†è¯´æ˜

### åç«¯æŠ€æœ¯æ ˆ

#### FastAPIæ¡†æ¶é€‰æ‹©ç†ç”±
```yaml
ä¼˜åŠ¿:
  - åŸç”Ÿå¼‚æ­¥æ”¯æŒï¼Œé€‚åˆAI APIé›†æˆ
  - è‡ªåŠ¨APIæ–‡æ¡£ç”Ÿæˆ
  - ç±»å‹å®‰å…¨å’Œæ•°æ®éªŒè¯
  - é«˜æ€§èƒ½ï¼Œæ¥è¿‘Flaskçš„2-3å€
  - ç°ä»£Pythonç‰¹æ€§æ”¯æŒ

ä¸æ›¿ä»£æ–¹æ¡ˆå¯¹æ¯”:
  vs Django: æ›´è½»é‡ï¼Œå¼‚æ­¥æ”¯æŒæ›´å¥½
  vs Flask: æ›´ç°ä»£ï¼Œç±»å‹å®‰å…¨ï¼Œæ€§èƒ½æ›´é«˜
  vs Express.js: Pythonç”Ÿæ€ï¼ŒAIé›†æˆæ›´å‹å¥½
```

#### SQLite vs PostgreSQL
```yaml
Stage 0 - SQLite:
  ä¼˜åŠ¿: é›¶é…ç½®ï¼Œæ–‡ä»¶æ•°æ®åº“ï¼Œç®€åŒ–éƒ¨ç½²
  åŠ£åŠ¿: å¹¶å‘æ”¯æŒæœ‰é™ï¼ŒåŠŸèƒ½ç›¸å¯¹ç®€å•
  
Stage 1+ - PostgreSQL:
  ä¼˜åŠ¿: å¼ºå¤§å¹¶å‘æ”¯æŒï¼Œä¸°å¯ŒåŠŸèƒ½ï¼ŒJSONæ”¯æŒ
  å‡çº§è·¯å¾„: æ•°æ®è¿ç§»è„šæœ¬ï¼ŒORMå…¼å®¹
```

### å‰ç«¯æŠ€æœ¯æ ˆ

#### React + TypeScript
```yaml
é€‰æ‹©ç†ç”±:
  - ç»„ä»¶åŒ–å¼€å‘ï¼Œä¾¿äºAIä»£ç ç”Ÿæˆ
  - TypeScriptæä¾›ç±»å‹å®‰å…¨
  - ä¸°å¯Œçš„UIç»„ä»¶åº“ç”Ÿæ€
  - ä¼˜ç§€çš„å¼€å‘è€…å·¥å…·

æŠ€æœ¯ç»†èŠ‚:
  çŠ¶æ€ç®¡ç†: Redux Toolkit + RTK Query
  UIç»„ä»¶åº“: Ant Design / Material-UI
  å›¾è¡¨å¯è§†åŒ–: D3.js + React-vis
  å®æ—¶é€šä¿¡: Socket.io-client
```

### AIé›†æˆæŠ€æœ¯

#### æœ¬åœ°AIèƒ½åŠ›é›†æˆ
```python
class LocalAIIntegration:
    def __init__(self):
        self.client = LocalAIClient()
        self.rate_limiter = AsyncLimiter(max_rate=10, time_period=60)
        
    async def understand_requirement(self, text: str) -> dict:
        async with self.rate_limiter:
            response = await self.client.process_text(
                text=text,
                max_tokens=4000,
                temperature=0.1,
                system_prompt=REQUIREMENT_ANALYSIS_PROMPT
            )
            return json.loads(response.content)
```

#### PromptX MCPé›†æˆ
```python
class PromptXIntegration:
    def __init__(self):
        self.mcp_client = MCPClient()
        
    async def activate_role(self, role_name: str):
        return await self.mcp_client.call_tool(
            "promptx_action",
            {"role": role_name}
        )
        
    async def remember_experience(self, content: str, tags: str):
        return await self.mcp_client.call_tool(
            "promptx_remember",
            {"content": content, "tags": tags}
        )
```

---

## ğŸ” å®‰å…¨æ¶æ„è®¾è®¡

### è®¤è¯å’Œæˆæƒ

#### JWTä»¤ç‰Œè®¤è¯
```python
class AuthenticationService:
    def __init__(self):
        self.secret_key = settings.JWT_SECRET_KEY
        self.algorithm = "HS256"
        
    def create_access_token(self, user_id: int) -> str:
        payload = {
            "user_id": user_id,
            "exp": datetime.utcnow() + timedelta(hours=24),
            "iat": datetime.utcnow(),
            "type": "access"
        }
        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
        
    def verify_token(self, token: str) -> dict:
        try:
            payload = jwt.decode(
                token, self.secret_key, algorithms=[self.algorithm]
            )
            return payload
        except jwt.ExpiredSignatureError:
            raise AuthenticationError("Token expired")
        except jwt.InvalidTokenError:
            raise AuthenticationError("Invalid token")
```

#### APIå¯†é’¥ç®¡ç†
```python
class AIConfigManager:
    def __init__(self):
        self.config_client = ConfigClient()
        
    async def get_ai_endpoint(self) -> str:
        # ä»é…ç½®ç®¡ç†è·å–AIæœåŠ¡ç«¯ç‚¹
        endpoint = await self.config_client.get_config("local-ai-endpoint")
        return endpoint.value
        
    async def update_ai_config(self):
        # æ›´æ–°AIæœåŠ¡é…ç½®
        new_config = await self.generate_new_config()
        await self.config_client.store_config("local-ai-endpoint", new_config)
```

### æ•°æ®å®‰å…¨

#### æ•æ„Ÿæ•°æ®åŠ å¯†
```python
class DataEncryption:
    def __init__(self):
        self.fernet = Fernet(settings.ENCRYPTION_KEY)
        
    def encrypt_user_data(self, data: str) -> str:
        return self.fernet.encrypt(data.encode()).decode()
        
    def decrypt_user_data(self, encrypted_data: str) -> str:
        return self.fernet.decrypt(encrypted_data.encode()).decode()
```

#### APIé™æµä¿æŠ¤
```python
class RateLimiter:
    def __init__(self):
        self.redis = redis.Redis()
        
    async def check_rate_limit(self, user_id: int, endpoint: str) -> bool:
        key = f"rate_limit:{user_id}:{endpoint}"
        current = await self.redis.get(key)
        
        if current is None:
            await self.redis.setex(key, 3600, 1)
            return True
            
        if int(current) >= settings.RATE_LIMIT_PER_HOUR:
            return False
            
        await self.redis.incr(key)
        return True
```

---

## ğŸ“ˆ ç›‘æ§å’Œå¯è§‚æµ‹æ€§

### æ€§èƒ½ç›‘æ§

#### PrometheusæŒ‡æ ‡æ”¶é›†
```python
from prometheus_client import Counter, Histogram, Gauge, generate_latest

# ä¸šåŠ¡æŒ‡æ ‡
requirement_processing_time = Histogram(
    'requirement_processing_duration_seconds',
    'Time spent processing requirements'
)

plan_generation_counter = Counter(
    'plan_generation_total',
    'Total number of plans generated'
)

active_windows_gauge = Gauge(
    'active_windows_current',
    'Current number of active development windows'
)

@requirement_processing_time.time()
async def process_requirement(text: str):
    # å¤„ç†éœ€æ±‚çš„ä»£ç 
    pass
```

#### åº”ç”¨ç›‘æ§
```python
class ApplicationMonitor:
    def __init__(self):
        self.metrics = MetricsCollector()
        
    async def track_user_action(self, user_id: int, action: str):
        await self.metrics.increment_counter(
            "user_actions_total",
            {"user_id": user_id, "action": action}
        )
        
    async def track_ai_api_call(self, api_name: str, duration: float):
        await self.metrics.record_histogram(
            "ai_api_call_duration",
            duration,
            {"api": api_name}
        )
```

### æ—¥å¿—ç®¡ç†

#### ç»“æ„åŒ–æ—¥å¿—
```python
import structlog

logger = structlog.get_logger()

class LoggingMiddleware:
    async def __call__(self, request: Request, call_next):
        start_time = time.time()
        
        logger.info(
            "request_started",
            method=request.method,
            url=str(request.url),
            user_id=getattr(request.state, "user_id", None)
        )
        
        response = await call_next(request)
        
        logger.info(
            "request_completed",
            method=request.method,
            url=str(request.url),
            status_code=response.status_code,
            duration=time.time() - start_time
        )
        
        return response
```

---

## ğŸš€ éƒ¨ç½²æ¶æ„

### Stage 0éƒ¨ç½²æ–¹æ¡ˆ

#### Dockerå®¹å™¨åŒ–
```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Docker Composeé…ç½®
```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=sqlite:///./tianting.db
      - REDIS_URL=redis://redis:6379
      - LOCAL_AI_ENDPOINT=${LOCAL_AI_ENDPOINT}
    depends_on:
      - redis
    volumes:
      - ./data:/app/data
      
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    depends_on:
      - api

volumes:
  redis_data:
```

### Stage 1+éƒ¨ç½²æ–¹æ¡ˆ

#### Kuberneteséƒ¨ç½²
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tianting-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: tianting-api
  template:
    metadata:
      labels:
        app: tianting-api
    spec:
      containers:
      - name: api
        image: tianting/api:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: tianting-secrets
              key: database-url
        - name: REDIS_URL
          value: "redis://redis-service:6379"
```

---

## ğŸ¯ æŠ€æœ¯å€ºåŠ¡ç®¡ç†

### ä»£ç è´¨é‡ä¿è¯

#### è‡ªåŠ¨åŒ–æ£€æŸ¥
```yaml
pre-commité…ç½®:
  - repo: local
    hooks:
      - id: pytest
        name: pytest
        entry: pytest
        language: system
        pass_filenames: false
        
      - id: black
        name: black
        entry: black
        language: system
        types: [python]
        
      - id: isort
        name: isort
        entry: isort
        language: system
        types: [python]
        
      - id: mypy
        name: mypy
        entry: mypy
        language: system
        types: [python]
```

#### æµ‹è¯•ç­–ç•¥
```python
# å•å…ƒæµ‹è¯•ç¤ºä¾‹
class TestRequirementParser:
    @pytest.fixture
    def parser(self):
        return RequirementParser()
        
    async def test_parse_web_app_requirement(self, parser):
        input_text = "æˆ‘æƒ³åšä¸€ä¸ªåœ¨çº¿éŸ³ä¹æ’­æ”¾å™¨"
        result = await parser.parse_requirement(input_text)
        
        assert result.project_type == ProjectType.WEB_APP
        assert "éŸ³ä¹" in [f.name for f in result.core_features]
        assert result.estimated_complexity == ComplexityLevel.MEDIUM

# é›†æˆæµ‹è¯•ç¤ºä¾‹  
class TestProjectPlanningFlow:
    async def test_complete_planning_flow(self):
        # æµ‹è¯•ä»éœ€æ±‚åˆ°è§„åˆ’çš„å®Œæ•´æµç¨‹
        requirement = await submit_requirement("ç”µå•†ç½‘ç«™")
        plan = await generate_plan(requirement.id)
        adjusted_plan = await adjust_plan(plan.id, "é¢„ç®—æ§åˆ¶åœ¨10ä¸‡")
        
        assert plan.budget.total > adjusted_plan.budget.total
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

#### è´Ÿè½½æµ‹è¯•
```python
import locust

class TiantingUser(HttpUser):
    wait_time = between(1, 3)
    
    @task(3)
    def submit_requirement(self):
        self.client.post("/api/v1/requirements", json={
            "text": "æˆ‘æƒ³åšä¸€ä¸ªç¤¾äº¤åº”ç”¨",
            "project_type": "mobile_app"
        })
    
    @task(1) 
    def generate_plan(self):
        self.client.post("/api/v1/plans/generate", json={
            "requirement_id": 1
        })
```

---

**ğŸ—ï¸ é€šè¿‡ç³»ç»ŸåŒ–çš„æŠ€æœ¯æ¶æ„è®¾è®¡ï¼Œç¡®ä¿å¤©åº­ç³»ç»Ÿèƒ½å¤Ÿé«˜æ•ˆã€ç¨³å®šã€å®‰å…¨åœ°ä¸ºç”¨æˆ·æä¾›"è¨€å‡ºæ³•éš"çš„å¼€å‘ä½“éªŒï¼**