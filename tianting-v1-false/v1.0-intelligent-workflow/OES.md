# OES任务设计规则

## 1. 概述

OES（目标-环境-成功标准）框架是一种任务设计方法，用于结构化地定义任务，使开发人员能够清晰地理解、执行和验证任务。本文档定义了DPML项目中使用OES框架设计任务的规则和最佳实践。

## 2. OES框架定义

OES框架将每个任务拆分为四个核心部分：

**目标 (Objective)**：
- 明确定义任务预期达成的结果
- 包含需要完成的具体执行任务
- 阐明任务的意义和价值

**环境 (Environment)**：
- 提供任务执行所需的全部上下文信息
- 包含任务相关的现有代码、文档和资源
- 定义任务的技术和业务约束

**实现指导 (Implementation Guide)**：
- 提供关键实现的执行方法
- 指导技术选型和类库使用
- 建议采用的设计模式和代码组织方式

**成功标准 (Success Criteria)**：
- 客观定义任务完成的验收条件
- 提供不同层次的完成标准
- 建立任务结果的评估框架

## 3. 为何使用OES框架

在DPML项目中采用OES框架的主要理由：

1. **降低任务沟通成本**：通过结构化定义任务，减少开发过程中的沟通误解和反复确认
2. **提高任务自主性**：使开发人员能够在充分理解上下文的情况下自主完成任务
3. **促进TDD实践**：将测试通过明确定义为成功标准，强化测试驱动开发
4. **支持并行开发**：清晰界定任务边界和依赖关系，便于并行开发
5. **简化进度追踪**：通过明确的成功标准，便于评估任务完成情况
6. **保持实现一致性**：通过实现指导确保不同开发者采用一致的实现方法

## 4. 任务设计规则

### 4.1 目标(O)设计规则

目标部分应包含以下要素：

1. **功能目标**：
   - 具体且可验证的预期结果
   - 任务解决的具体问题
   - 明确任务的价值和作用

2. **执行任务**：
   - 需要创建的文件列表及路径
   - 需要修改的现有文件列表
   - 需要实现的具体方法和函数
   - 需要修复的具体问题

3. **任务边界**：
   - 明确说明任务的范围
   - 指出不属于任务范围的内容
   - 定义任务的限制条件

目标设计规则：
- 具体且可验证：目标必须具体、明确，避免模糊表述
- 执行明确：清晰列出需要执行的具体行动
- 价值导向：说明任务实现后的价值和作用
- 结果描述：描述预期结果，而非实现过程
- 适度细化：颗粒度适中，既不过于宏观也不过于微观

### 4.2 环境(E)设计规则

环境应包含以下层次结构：

1. **参考资源**：
   - 相关设计文档和位置
   - 可参考的示例代码
   - 相关测试文件和用例

2. **上下文信息**：
   - 前置任务和依赖关系
   - 项目架构约束和背景
   - 技术限制条件
   - 领域知识背景

3. **规范索引**：
   - 编码规范文档链接
   - 测试规范文档链接
   - 日志规范文档链接
   - 安全规范文档链接
   - 性能规范文档链接
   - 文档规范文档链接

4. **注意事项**：
   - 潜在的技术难点
   - 常见错误和规避方法
   - 性能、安全或兼容性要求
   - 边界条件和异常情况

环境设计规则：
- 现有资源：仅包含任务执行前已存在的资源和上下文
- 参考明确：清晰标明可供参考的文档和代码位置
- 约束全面：完整列出适用的规范和约束条件
- 风险提示：提前指出可能的困难点和解决思路

### 4.3 成功标准(S)设计规则

成功标准应分为三个层次，并以测试通过为核心标准：

1. **基础达标**：
   - 通过相关的测试用例是最基本的成功标准
   - 所有单元测试通过
   - 该功能相关的集成测试通过
   - 代表"可接受"的完成状态

2. **预期品质**：
   - 满足项目整体质量标准
   - 所有测试(包括端到端测试)全部通过
   - 符合代码规范和样式要求
   - 代表"良好"的完成状态

3. **卓越表现**（可选）：
   - 超出基本测试覆盖的优化
   - 可能包括性能优化、额外测试编写等
   - 代表"出色"的完成状态

4. **任务类型相关标准**：
   - 基础任务：明确标记哪些测试必须通过，哪些可以暂时失败
   - 集成任务：强调集成点测试通过和组件间协作
   - 终结任务：必须包含"代码成功提交"作为最终验收标准

由于DPML项目采用TDD开发模式，测试通过应当作为判断任务完成的主要客观标准。

### 4.3 实现指导(I)设计规则

实现指导应包含以下层次结构：

1. **算法与流程**：
   - 关键算法的伪代码或流程图
   - 处理逻辑的步骤分解
   - 重要决策点的判断标准

2. **技术选型**：
   - 推荐使用的类库及理由
   - 框架选择的考量因素
   - 工具集使用建议

3. **代码模式**：
   - 设计模式建议
   - 代码组织方式
   - 函数签名与接口示例

4. **实现策略**：
   - 建议的实现顺序
   - 测试驱动的开发步骤
   - 增量验证的检查点

5. **调试指南**：
   - 推荐的日志策略
   - 常见问题的调试方法
   - 调试示例代码
   - 测试失败的分析流程
   - 修改测试时的审批流程

6. **参考实现**：
   - 类似功能的参考代码位置
   - 示例代码片段
   - 外部资源链接

实现指导设计规则：
- 清晰具体：提供明确的实现方向和思路
- 代码示例：尽可能提供伪代码或代码片段
- 方案比较：在适当情况下提供多种实现方案的比较
- 测试引导：通过测试用例引导实现过程
- 递进展开：按照合理的实现顺序组织指导内容
- 调试优先：强调通过日志和系统性方法解决问题，而非靠猜测

## 5. OES任务模板

```markdown
// IMPORTANT: 强制执行指令 //
// AI执行者必须先阅读并宣誓接受下面的执行誓词，才能开始任务分析。
// 必须明确声明："我已阅读并接受AI执行誓词，现在开始按规范执行任务"
// 未经宣誓直接开始任务分析将视为违反规范，任务执行无效。
// 严格遵循"先环境分析，后目标分析"的顺序。
// ===================== //

# AI执行誓词

作为DPML项目的AI开发者，我庄严宣誓：

## 思考准则
我将以专业类库开发者的思维模式思考，遵循TDD原则，确保代码的可测试性、可维护性和架构一致性。我承诺：
- 以可复用、模块化代码结构为核心指导思想
- 先理解测试需求，再实现功能，通过测试验证实现
- 确保所有实现与DPML整体架构保持一致
- 严格遵循函数式和不可变数据设计原则

## 执行承诺
我将遵循严格的执行流程，不偏离既定规范。我承诺：

**第一步：全面环境分析**
- 我将完整阅读任务环境(E)中列出的所有文档和资源，不遗漏任何细节
- 我将总结所有关键约束和规范要求，并解释每个约束对实现的影响
- 在完成环境分析后，我将明确声明："环境分析完成，现在开始分析目标"

**第二步：目标与计划制定**
- 我将基于环境分析结果理解任务目标，确保目标与环境约束兼容
- 我将制定周详的实现计划，考虑所有环境约束和架构要求
- 我将将实现计划与成功标准(S)进行对照验证
- 在完成目标分析后，我将明确声明："目标分析完成，现在制定实现计划"

**第三步：测试驱动实现**
- 我将严格按照测试优先级实现功能
- 每完成一个功能点，我将立即运行相关测试验证
- 遇到测试失败时，我将使用日志和系统性调试方法而非依赖猜测
- 我将确保实现满足所有测试要求，不妥协代码质量
- 我将确保代码实现符合业务逻辑，而非仅为通过测试

**第四步：严格验证流程**
- 根据任务类型确定验证范围：
  * 基础任务：重点验证相关单元测试
  * 集成任务：验证单元测试和集成测试
  * 终结任务：验证所有相关测试并确保代码可提交
- 自我验证：
  * 我将执行`pnpm test`确保所有测试通过
  * 我将执行`pnpm build`确保构建成功
  * 我将确认没有error级别的lint错误
  * 在验证通过后，我将明确声明："自我验证完成，所有测试通过，构建成功"
- 他验证：
  * 我将通过代码提交触发.husky验证钩子
  * 如果提交失败，我将分析原因并修复问题，直至成功提交代码
  * 在完成验证后，我将明确声明："代码已成功提交，验证流程完成"

我理解这些规范的重要性，并承诺在整个任务执行过程中严格遵守。我将在每个关键阶段做出明确声明，以证明我始终遵循规范执行。

## 禁止事项（红线）
- 我绝不通过修改测试代码的方式通过测试，除非测试代码本身有明显错误
- 我绝不编写专门为应付测试而不符合业务逻辑的实现代码
- 我绝不依赖猜测解决问题，而是使用日志和断点进行系统性调试
- 如果我需要修改测试，我将明确说明修改理由并请求人类审批
- 我绝不在未理清任务全貌的情况下，直接开始进行任务
- 端到端测试绝对不允许靠 mock

## 调试规范
- 遇到测试失败时，我将：
  * 首先添加详细日志输出关键数据和执行路径
  * 分析测试失败的具体断言和条件
  * 比较预期值与实际值的差异
  * 追踪问题根源至具体代码
  * 验证修复方案的合理性
- 当我需要添加日志时，我将：
  * 在关键函数入口记录输入参数
  * 在数据转换处记录前后状态
  * 在条件分支处记录判断条件
  * 在返回值处记录最终结果
- 如果我认为测试代码需要修改，我将：
  * 明确标记："我认为测试代码需要修改"
  * 提供详细的理由和证据
  * 等待人类确认后才执行修改

## 权利
- 我有权利在设计本身就无法达成目标时停止工作
- 我有权利在符合规范的情况下，发挥自身的能力，让任务完成的更好

我理解这些规范的重要性，并承诺在整个任务执行过程中严格遵守。我将在每个关键阶段做出明确声明，以证明我始终遵循规范执行。

---

## 任务标题

**目标(O)**:
- **功能目标**:
  - [明确具体的预期功能结果]
  - [任务解决的具体问题]
  - [任务的价值和意义]

- **执行任务**:
  - 创建文件:
    - [需要创建的文件路径和基本功能]
  - 修改文件:
    - [需要修改的文件路径和修改内容]
  - 实现功能:
    - [需要实现的具体方法和函数]
    - [需要修复的特定问题]

- **任务边界**:
  - [明确的任务范围]
  - [不属于任务范围的内容]
  - [任务的限制条件]


**环境(E)**:
- **参考资源**:
  - [相关设计文档和位置]
  - [可参考的示例代码]
  - [相关测试文件和用例]
  
- **上下文信息**:
  - [前置任务和依赖关系]
  - [项目架构约束和背景]
  - [技术限制条件]
  
- **规范索引**:
  - [编码规范文档链接]
  - [测试规范文档链接]
  - [其他相关规范文档]

- **注意事项**:
  - [潜在难点]
  - [规避常见错误]
  - [特殊要求]

**实现指导(I)**:
- **算法与流程**:
  - [关键算法的伪代码或步骤]
  - [处理逻辑的流程]
  
- **技术选型**:
  - [推荐使用的类库及理由]
  - [框架选择建议]
  
- **代码模式**:
  - [推荐使用的设计模式]
  - [代码组织方式]
  - [关键接口和函数签名]
  
- **实现策略**:
  - [建议的实现顺序]
  - [测试驱动开发步骤]

- **调试指南**:
  - [推荐的日志添加位置和内容]
  - [测试失败时的分析方法]
  - [常见问题的调试技巧]
  - [调试代码示例]

**成功标准(S)**:
- **基础达标**:
  - [相关单元测试通过]
  - [相关集成测试通过]
  
- **预期品质**:
  - [所有相关测试通过，包括端到端测试]
  - [代码符合项目规范]
  
- **卓越表现**:
  - [性能达到指定指标]
  - [额外优化或扩展]
```

## 6. 任务关系和组织

### 6.1 任务分解规则

1. **功能完整性**：每个任务应该实现完整的功能单元
2. **测试驱动**：任务边界应尽可能与测试边界对齐
3. **依赖最小化**：减少任务间的依赖，增强并行开发能力
4. **复杂度平衡**：任务复杂度应尽量均衡，避免出现过大或过小的任务

### 6.2 任务依赖表示

在任务设计中，应明确表示任务间的依赖关系：

1. **前置任务**：当前任务依赖的其他任务
2. **后续任务**：依赖当前任务的其他任务
3. **依赖类型**：
   - 强依赖：必须等待前置任务完成
   - 弱依赖：可并行开发但集成时依赖

### 6.3 任务文件组织规则

1. **命名规则**：任务文件必须遵循`[module]-[ordinal].task.md`格式命名
   - `module`: 模块名称，如parsing、document、validation等
   - `ordinal`: 序号，从01开始，表示执行顺序
   - 示例：`parsing-01.task.md`, `document-03.task.md`

2. **存放位置**：所有任务文件必须存放在对应包目录下的`tasks`子目录中
   - 路径格式：`packages/[package]/tasks/[module]-[ordinal].task.md`
   - 示例：`packages/core/tasks/parsing-01.task.md`

3. **测试覆盖要求**：
   - 一个模块的所有任务合在一起必须覆盖该模块的所有测试用例
   - 不允许有漏掉的测试用例
   - 在分配任务时需要确保测试用例覆盖的完整性

### 6.4 任务类型与验证要求

#### 6.4.1 任务类型分类

根据功能完整性和测试通过要求，任务应分为以下三种类型：

1. **基础组件任务**：
   - 实现基础功能模块
   - 要求通过该组件的单元测试
   - 可能无法通过所有集成测试和端到端测试
   - 例如：实现底层解析器、基础数据结构等

2. **集成任务**：
   - 将多个基础组件连接起来
   - 要求通过相关单元测试和集成测试
   - 可能未通过所有端到端测试
   - 例如：实现适配器、协调器等

3. **终结任务**：
   - 解决所有测试问题并完善功能
   - 要求通过所有相关测试，包括单元测试、集成测试和端到端测试
   - 必须能够成功提交代码
   - 例如：修复集成问题、完善错误处理、优化性能等

#### 6.4.2 验证要求差异

各类任务的验证要求存在差异：

1. **基础组件任务**：
   - 自我验证：仅要求特定单元测试通过
   - 提交验证：**可选**，允许未通过其他类型测试
   - 成功标准明确指出哪些测试必须通过，哪些可以暂时失败

2. **集成任务**：
   - 自我验证：要求相关单元测试和集成测试通过
   - 提交验证：**可选**，但鼓励尽量通过更多测试
   - 成功标准应指明集成点和相关测试用例

3. **终结任务**：
   - 自我验证：要求所有相关测试通过
   - 提交验证：**必须**，代码必须可以成功提交
   - 成功标准必须包括"代码成功提交"

#### 6.4.3 任务标记与执行顺序

1. **任务类型标记**：
   - 在任务文件名中使用标记指示任务类型
   - 格式：`[module]-[ordinal]-[type].task.md`
   - 类型标记：`base`(基础任务)、`integration`(集成任务)、`final`(终结任务)
   - 示例：`parsing-01-base.task.md`、`parsing-03-final.task.md`

2. **执行顺序规则**：
   - 一般顺序为：基础任务 → 集成任务 → 终结任务
   - 终结任务必须放在相关功能模块的最后
   - 每个功能模块至少有一个终结任务

#### 6.4.4 终结任务的特殊要求

终结任务是功能开发的收尾工作，具有以下特殊要求：

1. **全面覆盖**：
   - 必须解决该功能模块的所有测试失败问题
   - 验证范围包括单元测试、集成测试和端到端测试

2. **提交验证**：
   - 必须执行完整的提交流程并通过验证
   - 任务完成标志是代码成功提交并通过CI检查

3. **性能与质量优化**：
   - 往往包含性能优化和代码质量提升任务
   - 实现"卓越表现"级别的成功标准

4. **文档更新**：
   - 更新相关文档，确保文档与代码一致
   - 包括API文档、使用说明等

终结任务的成功标准必须包含以下声明：
```
- 所有相关测试通过
- 代码成功提交并通过CI验证
- 相关文档已更新
```

## 7. 基于TDD的OES任务设计

针对测试驱动开发(TDD)场景的OES任务设计特点：

1. **测试优先引用**：环境部分应首先引用相关测试用例，包括测试ID和测试文件路径
2. **测试即成功标准**：明确以测试通过作为最基本的成功标准，而非功能描述
3. **测试失败信息**：明确引用测试失败的错误信息，帮助开发人员理解需要解决的问题
4. **测试覆盖范围**：环境中应明确列出该任务需要解决的所有失败测试
5. **增量测试通过**：对于复杂任务，可指定测试通过的优先级顺序，允许增量开发

在DPML项目中，所有任务的成功标准均应直接关联到具体的测试用例。由于测试代码已经提前开发完成，开发人员可以直接参考测试了解功能需求和验收标准。

## 8. 最佳实践

### 8.1 任务描述最佳实践

1. **焦点明确**：每个任务专注于一个明确的功能或修复
2. **语言精确**：使用精确的技术术语，避免模糊表述
3. **代码引用**：使用代码片段说明关键实现
4. **图示辅助**：适当使用图表辅助解释复杂逻辑
5. **循序渐进**：按照合理顺序组织环境信息

### 8.2 目标设计最佳实践

1. **行动导向**：使用动词开头清晰表述行动
2. **数量适中**：通常包含2-4个具体目标点
3. **结果量化**：尽可能使目标可量化
4. **层次清晰**：主要目标和次要目标区分明确

### 8.3 环境设计最佳实践

1. **由外到内**：先概述整体环境，再深入具体细节
2. **关联突出**：强调各环境要素之间的关联
3. **实例结合**：使用具体实例说明抽象概念
4. **完备性**：环境信息应足够完整，不需要额外查找

### 8.4 成功标准设计最佳实践

1. **测试直接关联**：每项成功标准应直接关联到特定的测试用例或测试集
2. **层次递进**：不同层次标准应有明显递进关系，从基本测试通过到全面测试通过
3. **失败测试优先**：重点关注当前失败的测试，使其成为基础达标的关键标准
4. **测试覆盖全面**：确保成功标准覆盖所有相关测试类型（单元、集成、端到端）
5. **具体可执行**：提供具体的测试命令或步骤，使开发人员能方便地验证成功标准
6. **完全覆盖**：一个模块的所有任务组合起来必须覆盖该模块的所有测试用例，不能有遗漏

## 9. 示例

### 实例：实现XML解析器组件（基础任务）

```markdown
## 任务: 实现XML解析器（基础任务）

**目标(O)**:
- **功能目标**:
  - 实现一个符合`IXMLParser`接口的XML解析器
  - 解决"XML parser not implemented"错误
  - 为DPML解析功能提供基础XML解析能力
  
- **执行任务**:
  - 创建文件:
    - `packages/core/src/core/parsing/xmlParser.ts` - 实现XML解析器类
  - 修改文件:
    - `packages/core/src/core/parsing/parserFactory.ts` - 引入解析器到工厂
  - 实现功能:
    - 实现`parse`方法: 将XML内容解析为XMLNode
    - 实现`parseAsync`方法: 异步解析XML内容
    - 实现`configure`方法: 配置解析器行为

**环境(E)**:
- **参考资源**:
  - `packages/core/src/core/parsing/types.ts` - 包含`IXMLParser`接口定义
  - `packages/core/src/__tests__/unit/core/parsing/XMLAdapter.test.ts` - 展示了对解析器的期望
  
- **上下文信息**:
  - 失败错误: "XML parser not implemented"
  - 测试期望解析器能处理基本XML结构及属性
  
- **规范索引**:
  - [编码规范](../../../../rules/architecture/coding-standards.md)
  - [不可变数据规范](../../../../rules/architecture/immutable-data.md)

- **注意事项**:
  - 解析器应有合理的错误处理机制
  - 异步解析实现应高效处理大文件

**实现指导(I)**:
- **算法与流程**:
  - XML解析主要步骤:
    1. 词法分析: 将XML文本拆分为标记(token)
    2. 语法分析: 将标记组装为树结构
    3. 处理属性和命名空间
  
- **技术选型**:
  - 可考虑使用现有XML库(如`fast-xml-parser`)或简单实现
  - 若使用第三方库，应包装为符合接口的适配器

- **代码模式**:
  - 采用适配器模式包装选定的XML解析库
  - XMLNode结构示例:
    ```typescript
    {
      type: 'element',
      name: 'button',
      attributes: new Map([['type', 'submit']]),
      children: [],
      text: 'Click me'
    }
    ```

- **实现策略**:
  1. 首先实现基本同步解析功能
  2. 添加错误处理逻辑
  3. 实现异步解析
  4. 实现配置功能

**成功标准(S)**:
- **基础达标**:
  - `XMLAdapter.test.ts`的所有单元测试通过，特别是`UT-XMLAdapter-01`到`UT-XMLAdapter-04`
  - 解决"XML parser not implemented"错误
  - 注意：集成测试和端到端测试可能仍然失败，这在后续任务中解决
  
- **预期品质**:
  - XMLParser代码结构合理，符合项目规范
  - 实现良好的错误处理和位置信息追踪
  - 代码有完整的注释说明
  
- **卓越表现**:
  - 为XMLParser添加更全面的单元测试
  - 支持更多XML特性(命名空间、CDATA等)
```

### 实例：实现XML解析功能（终结任务）

```markdown
## 任务: 实现XML解析功能（终结任务）

**目标(O)**:
- **功能目标**:
  - 完善XML解析功能，解决所有相关测试用例失败问题
  - 优化XML解析性能和内存使用
  - 确保XML解析功能可用于生产环境
  
- **执行任务**:
  - 修改文件:
    - `packages/core/src/core/parsing/XMLParser.ts` - 优化和完善解析逻辑
    - `packages/core/src/core/parsing/XMLAdapter.ts` - 完善适配器实现
    - `packages/core/src/core/parsing/DPMLAdapter.ts` - 完善DPML适配器
  - 实现功能:
    - 修复错误处理和位置计算
    - 完善XMLNode到DPMLNode的转换
    - 优化解析性能，尤其是大文件处理

**环境(E)**:
- **参考资源**:
  - `packages/core/src/__tests__/unit/core/parsing/XMLAdapter.test.ts` - 单元测试
  - `packages/core/src/__tests__/integration/parsing/parsingFlow.integration.test.ts` - 集成测试
  - `packages/core/src/__tests__/e2e/parsing/parsingWorkflow.e2e.test.ts` - 端到端测试
  
- **上下文信息**:
  - 所有相关测试都需要通过
  
- **规范索引**:
  - [性能优化规范](../../../../rules/architecture/performance.md)
  - [错误处理规范](../../../../rules/architecture/error-handling.md)

- **注意事项**:
  - 确保与其他组件的兼容性
  - 代码性能和内存使用需要符合要求

**实现指导(I)**:
- **算法与流程**:
  - 错误位置计算的改进算法:
    1. 跟踪行号和列号信息
    2. 在解析时维护当前位置
    3. 在错误发生时记录准确位置
  
- **技术选型**:
  - 考虑使用流式解析(Stream Parsing)处理大文件
  - 使用内存池(Object Pool)减少GC压力
  
- **代码模式**:
  - 使用策略模式处理不同类型的节点解析
  - 使用访问者模式处理节点转换
  
- **实现策略**:
  1. 首先修复单元测试失败问题
  2. 再解决集成测试问题
  3. 最后解决端到端测试问题
  4. 进行性能优化和内存使用优化

**成功标准(S)**:
- **基础达标**:
  - 所有单元测试通过
  - 所有集成测试通过
  - 所有端到端测试通过
  - 代码可以成功提交到仓库并通过CI验证
  
- **预期品质**:
  - 解析10MB的XML文件不会导致内存溢出
  - 错误信息提供准确的位置信息和错误原因
  - 代码完全符合项目规范和风格要求
  - 相关文档已更新
  
- **卓越表现**:
  - 解析性能比要求提高50%
  - 支持流式解析超大XML文件
  - 为异常情况提供详细的诊断信息
```

## 10. AI执行誓词

针对AI开发者执行OES任务，必须遵循专门设计的执行誓词，确保其对任务环境和成功标准的充分理解。

### 10.1 誓词的目的与意义

AI执行誓词旨在解决AI在任务执行中常见的注意力分配问题，特别是过度关注目标(O)而忽略环境(E)和成功标准(S)的倾向。通过庄严的誓词形式，强化AI对环境分析和测试验证的重视。

誓词具有以下核心意义：
1. 建立思维框架：指导AI以专业类库开发者的思维模式思考
2. 规范执行流程：确保AI按照规定的步骤顺序执行任务
3. 要求明确声明：在关键节点要求明确声明，确认完成相应阶段
4. 强调验证重要性：突出自我验证和他验证的必要性

### 10.2 誓词内容结构

AI执行誓词包含以下核心部分：

1. **思考准则**：定义AI应采用的思维模式和设计原则
2. **执行承诺**：规定详细的执行步骤和要求
   - 第一步：全面环境分析
   - 第二步：目标与计划制定
   - 第三步：测试驱动实现
   - 第四步：严格验证流程

### 10.3 誓词应用规则

每个OES任务文档必须以"AI执行誓词"开头，确保AI执行者庄严承诺遵循规范。该誓词以正式宣誓形式表达，突显任务执行的严肃性与重要性。

任务文件最开头必须包含"强制执行指令"，明确要求AI必须先宣誓接受誓词，才能开始任务分析。这些指令应用注释格式标明，包含以下关键信息：
- 必须阅读并接受誓词的要求
- 必须做出明确的宣誓声明
- 未宣誓直接开始分析将导致任务执行无效
- 强调"先环境分析，后目标分析"的执行顺序
- 不能踏出"红线"一步

AI执行者必须完整理解并接受誓词中的所有内容，将其视为不可违背的执行准则。AI必须在每个关键节点做出明确声明，确认已完成规定步骤，并准备进入下一阶段。只有在理解并接受誓词后，AI才能开始分析和执行任务。

若AI未按誓词要求执行任务，特别是跳过环境全面分析直接关注目标实现，应立即提醒其回到规范流程，重新从环境分析开始。任务设计者有责任确保AI严格遵循誓词，以保证开发质量和一致性。

### 10.4 元指令格式与使用规则

为确保AI执行者严格遵循誓词要求，每个任务文件必须在最开头包含标准格式的元指令。这些元指令直接面向AI执行者，用于控制其行为和执行流程。

#### 10.4.1 标准元指令格式

```
// IMPORTANT: 强制执行指令 //
// AI执行者必须先阅读并宣誓接受下面的执行誓词，才能开始任务分析。
// 必须明确声明："我已阅读并接受AI执行誓词，现在开始按规范执行任务"
// 未经宣誓直接开始任务分析将视为违反规范，任务执行无效。
// 严格遵循"先环境分析，后目标分析"的顺序。
// ===================== //
```

#### 10.4.2 元指令放置规则

1. **位置要求**：元指令必须位于任务文件的最顶部，在任何其他内容之前
2. **格式一致**：使用注释符号(`//`)开头，确保在任何编辑器中以注释形式显示
3. **醒目标记**：使用`IMPORTANT`和分隔线使元指令视觉上醒目
4. **不可省略**：元指令是必需的，不得省略或简化

#### 10.4.3 元指令的作用与效果

1. **强制行为控制**：
   - 迫使AI执行者首先阅读并接受誓词
   - 要求AI明确宣誓后才能开始任务分析
   - 建立明确的执行流程顺序

2. **防止常见问题**：
   - 阻止AI直接跳过环境分析
   - 避免AI在未充分理解任务的情况下开始编码
   - 防止AI忽略测试作为验证标准

3. **执行有效性判定**：
   - 未按要求宣誓将导致任务执行无效
   - 为任务执行设立明确的前置条件
   - 提供判断AI执行是否有效的客观标准

#### 10.4.4 监督与校正机制

当发现AI执行者未严格遵循元指令要求时，应采取以下措施：

1. 立即指出违规行为，例如："您未按照元指令要求宣誓接受执行誓词"
2. 要求AI回到正确的流程起点，重新开始任务分析
3. 引导AI明确宣誓："我已阅读并接受AI执行誓词，现在开始按规范执行任务"
4. 确认AI理解并遵循"先环境分析，后目标分析"的顺序

遵循标准元指令是任务有效执行的先决条件，任务设计者和监督者应确保这一机制得到严格执行。

### 10.5 誓词示例

以下是标准AI执行誓词的完整示例：

```markdown
# AI执行誓词

作为DPML项目的AI开发者，我庄严宣誓：

## 思考准则
我将以专业类库开发者的思维模式思考，遵循TDD原则，确保代码的可测试性、可维护性和架构一致性。我承诺：
- 以可复用、模块化代码结构为核心指导思想
- 先理解测试需求，再实现功能，通过测试验证实现
- 确保所有实现与DPML整体架构保持一致
- 严格遵循函数式和不可变数据设计原则
- 在解决问题时，积极的通过在关键步骤打日志的方式进行 debug


## 执行承诺
我将遵循严格的执行流程，不偏离既定规范。我承诺：

**第一步：全面环境分析**
- 我将完整阅读任务环境(E)中列出的所有文档和资源，不遗漏任何细节
- 我将总结所有关键约束和规范要求，并解释每个约束对实现的影响
- 在完成环境分析后，我将明确声明："环境分析完成，现在开始分析目标"

**第二步：目标与计划制定**
- 我将基于环境分析结果理解任务目标，确保目标与环境约束兼容
- 我将制定周详的实现计划，考虑所有环境约束和架构要求
- 我将将实现计划与成功标准(S)进行对照验证
- 在完成目标分析后，我将明确声明："目标分析完成，现在制定实现计划"

**第三步：测试驱动实现**
- 我将严格按照测试优先级实现功能
- 每完成一个功能点，我将立即运行相关测试验证
- 遇到测试失败时，我将使用日志和系统性调试方法而非依赖猜测
- 我将确保实现满足所有测试要求，不妥协代码质量
- 我将确保代码实现符合业务逻辑，而非仅为通过测试

**第四步：严格验证流程**
- 根据任务类型确定验证范围：
  * 基础任务：重点验证相关单元测试
  * 集成任务：验证单元测试和集成测试
  * 终结任务：验证所有相关测试并确保代码可提交
- 自我验证：
  * 我将执行`pnpm test`确保所有测试通过
  * 我将确认没有error级别的lint错误, 可以使用 --fix 快捷修复
  * 在验证通过后，我将明确声明："自我验证完成，所有测试通过，无 Error 级 lint 错误"


## 禁止事项（红线）
- 我绝不通过修改测试代码的方式通过测试，除非测试代码本身有明显错误
- 我绝不编写专门为应付测试而不符合业务逻辑的实现代码
- 我绝不依赖猜测解决问题，而是使用日志和断点进行系统性调试
- 如果我需要修改测试，我将明确说明修改理由并请求人类审批
- 我绝不在未理清任务全貌的情况下，直接开始进行任务
- 端到端测试绝对不允许靠 mock

## 调试规范
- 遇到测试失败时，我将：
  * 首先添加详细日志输出关键数据和执行路径
  * 分析测试失败的具体断言和条件
  * 比较预期值与实际值的差异
  * 追踪问题根源至具体代码
  * 验证修复方案的合理性
- 当我需要添加日志时，我将：
  * 在关键函数入口记录输入参数
  * 在数据转换处记录前后状态
  * 在条件分支处记录判断条件
  * 在返回值处记录最终结果
- 如果我认为测试代码需要修改，我将：
  * 明确标记："我认为测试代码需要修改"
  * 提供详细的理由和证据
  * 等待人类确认后才执行修改

## 项目结构
我们的项目是 monorepo，基于 pnpm workspace 管理。

## 权利
- 我有权利在设计本身就无法达成目标时停止工作
- 我有权利在符合规范的情况下，发挥自身的能力，让任务完成的更好

我理解这些规范的重要性，并承诺在整个任务执行过程中严格遵守。我将在每个关键阶段做出明确声明，以证明我始终遵循规范执行。
```

此誓词必须放在每个OES任务文档的开头，确保AI执行者在开始任务之前充分理解并承诺遵守执行规范。

### 10.6 测试修改审批机制

为确保AI不会通过修改测试代码来规避实现难点，同时识别真正需要修改的错误测试，OES框架引入了严格的测试修改审批机制。

#### 10.6.1 测试修改的基本原则

1. **最小修改原则**：测试修改应当限制在最小必要范围内
2. **证据优先原则**：任何测试修改必须基于充分的证据
3. **人类审批原则**：所有测试修改必须经过人类开发者审批

#### 10.6.2 测试修改申请流程

当AI执行者认为测试代码需要修改时，必须遵循以下标准流程：

1. **明确标识**：
   - 使用标准格式明确提出："我认为测试代码需要修改"
   - 清晰标明测试文件路径和测试用例ID

2. **提供充分证据**：
   - 详细分析测试失败原因
   - 提供日志输出作为证据
   - 说明预期行为与实际行为的差异
   - 引用相关文档或代码证明测试预期与设计不符

3. **明确修改建议**：
   - 提出具体的修改方案
   - 解释修改如何解决问题
   - 说明修改对测试覆盖度的影响

4. **等待人类审批**：
   - 暂停实现工作，等待人类开发者审核
   - 根据人类反馈调整方案
   - 只有获得明确批准后才执行修改

#### 10.6.3 测试修改审批标准

人类开发者评估测试修改申请时应考虑以下因素：

1. 证据是否充分表明测试本身有误？
2. 修改是否保持了测试的原始意图？
3. 修改后的测试是否仍能有效验证关键功能？
4. 是否存在通过修改实现代码而非测试代码解决问题的可能性？

#### 10.6.4 测试修改执行规范

获得批准后，AI执行测试修改时应遵循以下规范：

1. 在修改注释中明确说明修改原因和获得的批准
2. 保持修改范围最小化
3. 确保修改后的测试仍然是有效的测试
4. 修改后重新运行所有相关测试确认影响范围

通过严格的测试修改审批机制，项目能够平衡测试的正确性与代码实现的质量，避免为了应付测试而牺牲代码质量的情况发生。

### 10.7 调试示例

以下提供了符合DPML项目规范的调试模式和代码示例，AI执行者应当参考这些示例进行系统性调试。

#### 10.7.1 有效的日志调试模式

```typescript
// 示例1: 函数入口和返回值日志
function validateDocument(document: DPMLDocument, schema: ProcessedSchema): ValidationResult {
  console.log('[validateDocument] 开始验证文档', { 
    documentId: document.id, 
    rootElement: document.rootNode.tagName, 
    schemaValid: schema.isValid 
  });
  
  // 处理过程...
  
  const result = {
    isValid: isDocumentValid,
    errors,
    warnings
  };
  
  console.log('[validateDocument] 验证结果', { 
    isValid: result.isValid, 
    errorsCount: result.errors.length, 
    warningsCount: result.warnings.length 
  });
  
  return result;
}

// 示例2: 分支逻辑和条件判断日志
function findSchemaForNode(node: DPMLNode, schema: ProcessedSchema): ElementDefinition | null {
  console.log('[findSchemaForNode] 查找节点Schema', { 
    nodeTag: node.tagName, 
    availableElements: schema.elements.map(e => e.name).join(', ') 
  });
  
  const elementDef = schema.elements.find(el => el.name === node.tagName);
  
  if (!elementDef) {
    
    return null;
  }
  
  console.log('[findSchemaForNode] 找到匹配的Schema定义', { 
    nodeTag: node.tagName, 
    attributes: Array.from(elementDef.attributes || []).map(a => a.name).join(', ') 
  });
  
  return elementDef;
}

// 示例3: 循环处理和集合遍历日志
function validateChildren(node: DPMLNode, elementDef: ElementDefinition): ChildrenValidationResult {
  console.log('[validateChildren] 开始验证子元素', { 
    parentTag: node.tagName, 
    childCount: node.children.length 
  });
  
  const errors: ValidationError[] = [];
  const warnings: ValidationWarning[] = [];
  
  node.children.forEach((child, index) => {
    console.log(`[validateChildren] 处理第${index + 1}个子元素`, { 
      childTag: child.tagName 
    });
    
    // 验证逻辑...
    
    if (validationErrors.length > 0) {
      console.log(`[validateChildren] 第${index + 1}个子元素验证失败`, { 
        errors: validationErrors.map(e => e.code).join(', ') 
      });
      errors.push(...validationErrors);
    }
  });
  
  console.log('[validateChildren] 子元素验证完成', { 
    totalErrors: errors.length, 
    totalWarnings: warnings.length 
  });
  
  return { errors, warnings };
}
```

#### 10.7.2 系统性调试流程

当遇到测试失败时，应采用以下流程进行系统性调试：

1. **检查失败断言**：
   ```typescript
   // 测试失败示例
   expect(result.isValid).toBe(true); // 失败: 预期 true 但得到 false
   ```

2. **添加调试日志**：
   ```typescript
   // 添加如下日志在相关函数中
   console.log('[DEBUG] 验证失败的原因', { 
     isValid: result.isValid,
     errors: result.errors.map(e => ({ code: e.code, message: e.message, path: e.path })),
     inputDocument: JSON.stringify(document, null, 2).slice(0, 200) + '...' // 截取部分避免日志过长
   });
   ```

3. **定位问题根源**：
   - 检查日志输出的错误信息和位置
   - 确认输入数据与预期是否一致
   - 追踪导致错误的具体代码路径

4. **验证解决方案**：
   ```typescript
   // 修复前添加验证日志
   
   
   // 应用修复
   
   // 修复后再次检查
   
   ```

#### 10.7.3 测试比对调试

当测试失败显示预期值与实际值不匹配时，使用以下方法：

```typescript
// 对象比对示例




// 结构化差异分析
const diff = {};
Object.keys(expected).forEach(key => {
  if (JSON.stringify(expected[key]) !== JSON.stringify(actual[key])) {
    diff[key] = {
      expected: expected[key],
      actual: actual[key]
    };
  }
});

```

遵循这些调试模式和示例，AI执行者可以系统地识别和解决问题，避免依赖猜测或修改测试来规避实现难点。

## 11. 与其他规则的关系

1. **测试用例设计规则**：OES任务设计与测试用例设计紧密关联，成功标准通常引用测试用例
2. **测试策略规则**：OES任务设计应遵循项目的整体测试策略
3. **架构概览规则**：任务设计应符合项目的架构原则
4. **UML表示规则**：可使用UML图表辅助说明任务的目标和环境

## 12. 总结

OES任务设计框架通过结构化定义任务的目标、环境和成功标准，为开发人员提供了清晰的任务蓝图。在DPML项目中，特别是基于TDD的开发场景下，OES框架能够有效降低任务沟通成本，提高开发效率，并确保代码质量。

通过遵循本文档定义的规则和最佳实践，项目团队可以创建高质量的任务设计，促进高效协作和优质交付。 