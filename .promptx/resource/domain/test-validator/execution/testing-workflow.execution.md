<execution>
  <constraint>
    ## æµ‹è¯•éªŒè¯é™åˆ¶æ¡ä»¶
    - **æ—¶é—´çº¦æŸ**ï¼šæµ‹è¯•æ‰§è¡Œæ—¶é—´ä¸å¾—å½±å“å¼€å‘æ•ˆç‡
    - **èµ„æºçº¦æŸ**ï¼šæµ‹è¯•ç¯å¢ƒçš„è®¡ç®—å’Œå­˜å‚¨èµ„æºæœ‰é™
    - **ç¯å¢ƒçº¦æŸ**ï¼šæµ‹è¯•å¿…é¡»åœ¨éš”ç¦»ç¯å¢ƒä¸­è¿›è¡Œ
    - **æ•°æ®çº¦æŸ**ï¼šæµ‹è¯•æ•°æ®ä¸å¾—åŒ…å«æ•æ„Ÿä¿¡æ¯
    - **å…¼å®¹æ€§çº¦æŸ**ï¼šæµ‹è¯•å¿…é¡»æ”¯æŒå¤šç§è¿è¡Œç¯å¢ƒ
  </constraint>

  <rule>
    ## æµ‹è¯•éªŒè¯å¼ºåˆ¶è§„åˆ™
    - **å…¨è¦†ç›–åŸåˆ™**ï¼šå…³é”®åŠŸèƒ½å¿…é¡»æœ‰å®Œæ•´çš„æµ‹è¯•è¦†ç›–
    - **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**ï¼šå¯è‡ªåŠ¨åŒ–çš„æµ‹è¯•å¿…é¡»è‡ªåŠ¨åŒ–
    - **éš”ç¦»åŸåˆ™**ï¼šæµ‹è¯•ä¹‹é—´å¿…é¡»ç›¸äº’ç‹¬ç«‹
    - **å¯é‡å¤æ€§**ï¼šæµ‹è¯•ç»“æœå¿…é¡»å¯é‡å¤å’Œå¯éªŒè¯
    - **å¤±è´¥å¿«é€Ÿ**ï¼šæµ‹è¯•å¤±è´¥å¿…é¡»å¿«é€Ÿåé¦ˆå’Œå®šä½
  </rule>

  <guideline>
    ## æµ‹è¯•éªŒè¯æŒ‡å¯¼åŸåˆ™
    - **å·¦ç§»æµ‹è¯•**ï¼šå°½æ—©è¿›è¡Œæµ‹è¯•ï¼Œé™ä½ä¿®å¤æˆæœ¬
    - **é£é™©é©±åŠ¨**ï¼šä¼˜å…ˆæµ‹è¯•é«˜é£é™©å’Œå…³é”®åŠŸèƒ½
    - **æŒç»­é›†æˆ**ï¼šæµ‹è¯•ä¸å¼€å‘æµç¨‹æ·±åº¦é›†æˆ
    - **è´¨é‡å†…å»º**ï¼šå°†è´¨é‡ä¿è¯èå…¥å¼€å‘è¿‡ç¨‹
    - **æ•°æ®é©±åŠ¨**ï¼šåŸºäºæ•°æ®è¿›è¡Œæµ‹è¯•å†³ç­–
  </guideline>

  <process>
    ## ğŸ§ª æµ‹è¯•éªŒè¯å·¥ä½œæµç¨‹

    ### æµ‹è¯•é‡‘å­—å¡”æ¶æ„
    ```mermaid
    graph TD
        A[æµ‹è¯•é‡‘å­—å¡”] --> B[å•å…ƒæµ‹è¯•]
        A --> C[é›†æˆæµ‹è¯•]
        A --> D[ç«¯åˆ°ç«¯æµ‹è¯•]
        A --> E[æ¢ç´¢æ€§æµ‹è¯•]
        
        B --> B1[å‡½æ•°æµ‹è¯•]
        B --> B2[ç±»æµ‹è¯•]
        B --> B3[æ¨¡å—æµ‹è¯•]
        
        C --> C1[ç»„ä»¶é›†æˆ]
        C --> C2[æœåŠ¡é›†æˆ]
        C --> C3[æ•°æ®åº“é›†æˆ]
        
        D --> D1[ç”¨æˆ·åœºæ™¯æµ‹è¯•]
        D --> D2[ä¸šåŠ¡æµç¨‹æµ‹è¯•]
        D --> D3[ç³»ç»Ÿæµ‹è¯•]
        
        E --> E1[æ‰‹å·¥æ¢ç´¢]
        E --> E2[è¾¹ç•Œæµ‹è¯•]
        E --> E3[å¼‚å¸¸æµ‹è¯•]
    ```

    ### ç¬¬ä¸€é˜¶æ®µï¼šæµ‹è¯•è§„åˆ’ä¸è®¾è®¡
    ```mermaid
    flowchart TD
        A[éœ€æ±‚åˆ†æ] --> B[é£é™©è¯„ä¼°]
        B --> C[æµ‹è¯•ç­–ç•¥åˆ¶å®š]
        C --> D[æµ‹è¯•è®¡åˆ’ç¼–å†™]
        D --> E[æµ‹è¯•ç”¨ä¾‹è®¾è®¡]
        E --> F[æµ‹è¯•æ•°æ®å‡†å¤‡]
        F --> G[æµ‹è¯•ç¯å¢ƒæ­å»º]
        
        B --> B1[åŠŸèƒ½é£é™©]
        B --> B2[æ€§èƒ½é£é™©]
        B --> B3[å®‰å…¨é£é™©]
        B --> B4[é›†æˆé£é™©]
        
        C --> C1[æµ‹è¯•èŒƒå›´]
        C --> C2[æµ‹è¯•æ–¹æ³•]
        C --> C3[æµ‹è¯•å·¥å…·]
        C --> C4[æµ‹è¯•æ ‡å‡†]
        
        E --> E1[æ­£å‘æµ‹è¯•ç”¨ä¾‹]
        E --> E2[è´Ÿå‘æµ‹è¯•ç”¨ä¾‹]
        E --> E3[è¾¹ç•Œæµ‹è¯•ç”¨ä¾‹]
        E --> E4[å¼‚å¸¸æµ‹è¯•ç”¨ä¾‹]
    ```

    ### ç¬¬äºŒé˜¶æ®µï¼šæµ‹è¯•æ‰§è¡Œä¸ç›‘æ§
    ```mermaid
    graph TD
        A[æµ‹è¯•æ‰§è¡Œ] --> B[å•å…ƒæµ‹è¯•æ‰§è¡Œ]
        A --> C[é›†æˆæµ‹è¯•æ‰§è¡Œ]
        A --> D[ç³»ç»Ÿæµ‹è¯•æ‰§è¡Œ]
        A --> E[æ€§èƒ½æµ‹è¯•æ‰§è¡Œ]
        
        B --> B1[ä»£ç è¦†ç›–ç‡æ£€æŸ¥]
        B --> B2[æ–­è¨€éªŒè¯]
        B --> B3[Mockå¯¹è±¡æµ‹è¯•]
        
        C --> C1[æ¥å£æµ‹è¯•]
        C --> C2[æ•°æ®æµæµ‹è¯•]
        C --> C3[ç»„ä»¶åä½œæµ‹è¯•]
        
        D --> D1[åŠŸèƒ½éªŒè¯]
        D --> D2[ç”¨æˆ·ä½“éªŒæµ‹è¯•]
        D --> D3[å…¼å®¹æ€§æµ‹è¯•]
        
        E --> E1[è´Ÿè½½æµ‹è¯•]
        E --> E2[å‹åŠ›æµ‹è¯•]
        E --> E3[ç¨³å®šæ€§æµ‹è¯•]
    ```

    ### ç¬¬ä¸‰é˜¶æ®µï¼šç»“æœåˆ†æä¸æŠ¥å‘Š
    ```mermaid
    flowchart LR
        A[æµ‹è¯•ç»“æœ] --> B[æ•°æ®æ”¶é›†]
        B --> C[ç»“æœåˆ†æ]
        C --> D[é—®é¢˜åˆ†ç±»]
        D --> E[æŠ¥å‘Šç”Ÿæˆ]
        E --> F[æ”¹è¿›å»ºè®®]
        
        B --> B1[æµ‹è¯•é€šè¿‡ç‡]
        B --> B2[ä»£ç è¦†ç›–ç‡]
        B --> B3[æ€§èƒ½æŒ‡æ ‡]
        B --> B4[ç¼ºé™·ç»Ÿè®¡]
        
        C --> C1[è¶‹åŠ¿åˆ†æ]
        C --> C2[æ ¹å› åˆ†æ]
        C --> C3[å½±å“è¯„ä¼°]
        
        D --> D1[åŠŸèƒ½ç¼ºé™·]
        D --> D2[æ€§èƒ½é—®é¢˜]
        D --> D3[å®‰å…¨æ¼æ´]
        D --> D4[å…¼å®¹æ€§é—®é¢˜]
    ```

    ## ğŸ› ï¸ è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶

    ### Pythonæµ‹è¯•æ¡†æ¶å®ç°
    ```python
    import pytest
    import unittest
    from unittest.mock import Mock, patch
    import asyncio
    from typing import Dict, List, Any
    import time
    import psutil
    
    class TestFramework:
        def __init__(self):
            self.test_results = []
            self.performance_metrics = {}
            self.coverage_data = {}
        
        def run_unit_tests(self, test_modules: List[str]) -> Dict[str, Any]:
            """è¿è¡Œå•å…ƒæµ‹è¯•"""
            results = {}
            
            for module in test_modules:
                try:
                    # ä½¿ç”¨pytestè¿è¡Œæµ‹è¯•
                    exit_code = pytest.main(['-v', module, '--cov=.', '--cov-report=json'])
                    results[module] = {
                        'status': 'passed' if exit_code == 0 else 'failed',
                        'exit_code': exit_code
                    }
                except Exception as e:
                    results[module] = {
                        'status': 'error',
                        'error': str(e)
                    }
            
            return results
        
        async def run_integration_tests(self, test_configs: List[Dict]) -> Dict[str, Any]:
            """è¿è¡Œé›†æˆæµ‹è¯•"""
            results = {}
            
            for config in test_configs:
                test_name = config['name']
                try:
                    # æ‰§è¡Œé›†æˆæµ‹è¯•
                    result = await self.execute_integration_test(config)
                    results[test_name] = result
                except Exception as e:
                    results[test_name] = {
                        'status': 'error',
                        'error': str(e)
                    }
            
            return results
        
        async def execute_integration_test(self, config: Dict) -> Dict[str, Any]:
            """æ‰§è¡Œå•ä¸ªé›†æˆæµ‹è¯•"""
            start_time = time.time()
            
            # æ¨¡æ‹Ÿé›†æˆæµ‹è¯•æ‰§è¡Œ
            test_steps = config.get('steps', [])
            step_results = []
            
            for step in test_steps:
                step_result = await self.execute_test_step(step)
                step_results.append(step_result)
                
                if not step_result['success']:
                    break
            
            end_time = time.time()
            
            return {
                'status': 'passed' if all(r['success'] for r in step_results) else 'failed',
                'duration': end_time - start_time,
                'steps': step_results
            }
        
        async def execute_test_step(self, step: Dict) -> Dict[str, Any]:
            """æ‰§è¡Œæµ‹è¯•æ­¥éª¤"""
            step_type = step.get('type')
            
            if step_type == 'api_call':
                return await self.test_api_call(step)
            elif step_type == 'database_check':
                return await self.test_database_check(step)
            elif step_type == 'file_operation':
                return await self.test_file_operation(step)
            else:
                return {'success': False, 'error': f'Unknown step type: {step_type}'}
        
        async def test_api_call(self, step: Dict) -> Dict[str, Any]:
            """æµ‹è¯•APIè°ƒç”¨"""
            # æ¨¡æ‹ŸAPIè°ƒç”¨æµ‹è¯•
            return {'success': True, 'response_time': 0.1}
        
        async def test_database_check(self, step: Dict) -> Dict[str, Any]:
            """æµ‹è¯•æ•°æ®åº“æ£€æŸ¥"""
            # æ¨¡æ‹Ÿæ•°æ®åº“æµ‹è¯•
            return {'success': True, 'records_count': 100}
        
        async def test_file_operation(self, step: Dict) -> Dict[str, Any]:
            """æµ‹è¯•æ–‡ä»¶æ“ä½œ"""
            # æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œæµ‹è¯•
            return {'success': True, 'file_size': 1024}
    ```

    ### æ€§èƒ½æµ‹è¯•å®ç°
    ```python
    class PerformanceTestSuite:
        def __init__(self):
            self.metrics = {}
        
        async def run_load_test(self, target_url: str, concurrent_users: int, duration: int):
            """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
            start_time = time.time()
            tasks = []
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            for i in range(concurrent_users):
                task = asyncio.create_task(self.simulate_user_load(target_url, duration))
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            end_time = time.time()
            
            # åˆ†æç»“æœ
            successful_requests = sum(1 for r in results if isinstance(r, dict) and r.get('success'))
            total_requests = len(results)
            
            return {
                'duration': end_time - start_time,
                'concurrent_users': concurrent_users,
                'total_requests': total_requests,
                'successful_requests': successful_requests,
                'success_rate': successful_requests / total_requests if total_requests > 0 else 0,
                'requests_per_second': total_requests / (end_time - start_time)
            }
        
        async def simulate_user_load(self, target_url: str, duration: int):
            """æ¨¡æ‹Ÿç”¨æˆ·è´Ÿè½½"""
            start_time = time.time()
            request_count = 0
            
            while time.time() - start_time < duration:
                try:
                    # æ¨¡æ‹Ÿè¯·æ±‚
                    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿè¯·æ±‚å»¶è¿Ÿ
                    request_count += 1
                except Exception as e:
                    return {'success': False, 'error': str(e)}
            
            return {'success': True, 'requests': request_count}
        
        def monitor_system_resources(self, duration: int) -> Dict[str, Any]:
            """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨"""
            start_time = time.time()
            cpu_samples = []
            memory_samples = []
            
            while time.time() - start_time < duration:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_percent = psutil.virtual_memory().percent
                
                cpu_samples.append(cpu_percent)
                memory_samples.append(memory_percent)
            
            return {
                'cpu_usage': {
                    'avg': sum(cpu_samples) / len(cpu_samples),
                    'max': max(cpu_samples),
                    'min': min(cpu_samples)
                },
                'memory_usage': {
                    'avg': sum(memory_samples) / len(memory_samples),
                    'max': max(memory_samples),
                    'min': min(memory_samples)
                }
            }
    ```

    ## ğŸ“Š è´¨é‡åº¦é‡ä¸åˆ†æ

    ### æµ‹è¯•è¦†ç›–ç‡åˆ†æ
    ```python
    class CoverageAnalyzer:
        def __init__(self):
            self.coverage_data = {}
        
        def analyze_code_coverage(self, coverage_file: str) -> Dict[str, Any]:
            """åˆ†æä»£ç è¦†ç›–ç‡"""
            # æ¨¡æ‹Ÿè¦†ç›–ç‡åˆ†æ
            return {
                'line_coverage': 85.5,
                'branch_coverage': 78.2,
                'function_coverage': 92.1,
                'uncovered_lines': [45, 67, 89, 123],
                'critical_uncovered': ['error_handling', 'edge_cases']
            }
        
        def generate_coverage_report(self, coverage_data: Dict) -> str:
            """ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š"""
            report = f"""
            ä»£ç è¦†ç›–ç‡æŠ¥å‘Š
            ================
            è¡Œè¦†ç›–ç‡: {coverage_data['line_coverage']:.1f}%
            åˆ†æ”¯è¦†ç›–ç‡: {coverage_data['branch_coverage']:.1f}%
            å‡½æ•°è¦†ç›–ç‡: {coverage_data['function_coverage']:.1f}%
            
            æœªè¦†ç›–çš„å…³é”®åŒºåŸŸ:
            {', '.join(coverage_data['critical_uncovered'])}
            """
            return report
    ```

    ### ç¼ºé™·åˆ†æä¸åˆ†ç±»
    ```mermaid
    graph TD
        A[ç¼ºé™·å‘ç°] --> B[ç¼ºé™·åˆ†ç±»]
        B --> C[ä¸¥é‡æ€§è¯„ä¼°]
        C --> D[ä¼˜å…ˆçº§æ’åº]
        D --> E[ä¿®å¤å»ºè®®]
        
        B --> B1[åŠŸèƒ½ç¼ºé™·]
        B --> B2[æ€§èƒ½é—®é¢˜]
        B --> B3[å®‰å…¨æ¼æ´]
        B --> B4[å…¼å®¹æ€§é—®é¢˜]
        B --> B5[ç”¨æˆ·ä½“éªŒé—®é¢˜]
        
        C --> C1[è‡´å‘½ Critical]
        C --> C2[ä¸¥é‡ Major]
        C --> C3[ä¸€èˆ¬ Minor]
        C --> C4[è½»å¾® Trivial]
        
        D --> D1[P0 ç«‹å³ä¿®å¤]
        D --> D2[P1 æœ¬ç‰ˆæœ¬ä¿®å¤]
        D --> D3[P2 ä¸‹ç‰ˆæœ¬ä¿®å¤]
        D --> D4[P3 åç»­è€ƒè™‘]
    ```

    ## ğŸ”„ æŒç»­æµ‹è¯•ä¸æ”¹è¿›

    ### CI/CDé›†æˆ
    ```yaml
    # æµ‹è¯•æµæ°´çº¿é…ç½®ç¤ºä¾‹
    test_pipeline:
      stages:
        - unit_tests
        - integration_tests
        - performance_tests
        - security_tests
        - deployment_tests
      
      unit_tests:
        script:
          - python -m pytest tests/unit/ --cov=src/ --cov-report=xml
        coverage: '/TOTAL.*\s+(\d+%)$/'
        artifacts:
          reports:
            coverage_report:
              coverage_format: cobertura
              path: coverage.xml
      
      integration_tests:
        script:
          - python -m pytest tests/integration/ -v
        dependencies:
          - unit_tests
      
      performance_tests:
        script:
          - python tests/performance/load_test.py
        only:
          - main
          - release/*
    ```

    ### æµ‹è¯•æ•°æ®ç®¡ç†
    ```python
    class TestDataManager:
        def __init__(self):
            self.test_data_sets = {}
        
        def create_test_data(self, scenario: str) -> Dict[str, Any]:
            """åˆ›å»ºæµ‹è¯•æ•°æ®"""
            if scenario == 'user_registration':
                return {
                    'valid_user': {
                        'username': 'testuser',
                        'email': 'test@example.com',
                        'password': 'SecurePass123!'
                    },
                    'invalid_user': {
                        'username': '',
                        'email': 'invalid-email',
                        'password': '123'
                    }
                }
            elif scenario == 'memory_operations':
                return {
                    'sample_memories': [
                        {'content': 'Test memory 1', 'importance': 0.8},
                        {'content': 'Test memory 2', 'importance': 0.6}
                    ]
                }
            
            return {}
        
        def cleanup_test_data(self, scenario: str):
            """æ¸…ç†æµ‹è¯•æ•°æ®"""
            # å®ç°æµ‹è¯•æ•°æ®æ¸…ç†é€»è¾‘
            pass
    ```
  </process>

  <criteria>
    ## æµ‹è¯•éªŒè¯è¯„ä»·æ ‡å‡†

    ### æµ‹è¯•è¦†ç›–ç‡
    - âœ… ä»£ç è¡Œè¦†ç›–ç‡ â‰¥ 80%
    - âœ… åˆ†æ”¯è¦†ç›–ç‡ â‰¥ 75%
    - âœ… å‡½æ•°è¦†ç›–ç‡ â‰¥ 90%
    - âœ… å…³é”®è·¯å¾„è¦†ç›–ç‡ 100%

    ### æµ‹è¯•æ•ˆç‡
    - âœ… å•å…ƒæµ‹è¯•æ‰§è¡Œæ—¶é—´ â‰¤ 5åˆ†é’Ÿ
    - âœ… é›†æˆæµ‹è¯•æ‰§è¡Œæ—¶é—´ â‰¤ 30åˆ†é’Ÿ
    - âœ… è‡ªåŠ¨åŒ–æµ‹è¯•æ¯”ä¾‹ â‰¥ 80%
    - âœ… æµ‹è¯•ç»´æŠ¤æˆæœ¬åˆç†

    ### è´¨é‡æŒ‡æ ‡
    - âœ… æµ‹è¯•é€šè¿‡ç‡ â‰¥ 95%
    - âœ… ç¼ºé™·å‘ç°ç‡é«˜
    - âœ… è¯¯æŠ¥ç‡ â‰¤ 5%
    - âœ… å›å½’æµ‹è¯•æœ‰æ•ˆæ€§ â‰¥ 90%

    ### å¯ç»´æŠ¤æ€§
    - âœ… æµ‹è¯•ç”¨ä¾‹å¯è¯»æ€§å¼º
    - âœ… æµ‹è¯•æ•°æ®ç®¡ç†è§„èŒƒ
    - âœ… æµ‹è¯•ç¯å¢ƒç¨³å®š
    - âœ… æµ‹è¯•æ–‡æ¡£å®Œæ•´
  </criteria>
</execution>
