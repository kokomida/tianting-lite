<execution>
  <constraint>
    ## ç³»ç»Ÿè¿ç»´é™åˆ¶æ¡ä»¶
    - **å¯ç”¨æ€§çº¦æŸ**ï¼šç³»ç»Ÿå¯ç”¨æ€§å¿…é¡»è¾¾åˆ°99.5%ä»¥ä¸Š
    - **æ€§èƒ½çº¦æŸ**ï¼šç³»ç»Ÿå“åº”æ—¶é—´ä¸å¾—è¶…è¿‡ä¸šåŠ¡è¦æ±‚
    - **èµ„æºçº¦æŸ**ï¼šç¡¬ä»¶å’Œäº‘èµ„æºä½¿ç”¨æœ‰é¢„ç®—é™åˆ¶
    - **å®‰å…¨çº¦æŸ**ï¼šæ‰€æœ‰æ“ä½œå¿…é¡»ç¬¦åˆå®‰å…¨è§„èŒƒ
    - **åˆè§„çº¦æŸ**ï¼šå¿…é¡»ç¬¦åˆç›¸å…³æ³•è§„å’Œæ ‡å‡†è¦æ±‚
  </constraint>

  <rule>
    ## ç³»ç»Ÿè¿ç»´å¼ºåˆ¶è§„åˆ™
    - **å˜æ›´ç®¡ç†**ï¼šæ‰€æœ‰ç³»ç»Ÿå˜æ›´å¿…é¡»ç»è¿‡å®¡æ‰¹å’Œæµ‹è¯•
    - **å¤‡ä»½ç­–ç•¥**ï¼šå…³é”®æ•°æ®å¿…é¡»å®šæœŸå¤‡ä»½å’ŒéªŒè¯
    - **ç›‘æ§è¦†ç›–**ï¼šæ‰€æœ‰å…³é”®ç»„ä»¶å¿…é¡»æœ‰ç›‘æ§è¦†ç›–
    - **æ–‡æ¡£æ›´æ–°**ï¼šç³»ç»Ÿå˜æ›´å¿…é¡»åŒæ­¥æ›´æ–°æ–‡æ¡£
    - **æƒé™æ§åˆ¶**ï¼šä¸¥æ ¼æ§åˆ¶ç³»ç»Ÿè®¿é—®æƒé™
  </rule>

  <guideline>
    ## ç³»ç»Ÿè¿ç»´æŒ‡å¯¼åŸåˆ™
    - **é¢„é˜²ä¼˜äºæ²»ç–—**ï¼šé€šè¿‡ç›‘æ§å’Œé¢„è­¦é¢„é˜²é—®é¢˜
    - **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**ï¼šä¼˜å…ˆä½¿ç”¨è‡ªåŠ¨åŒ–å·¥å…·å’Œæµç¨‹
    - **æ ‡å‡†åŒ–æ“ä½œ**ï¼šå»ºç«‹æ ‡å‡†åŒ–çš„æ“ä½œæµç¨‹
    - **æŒç»­æ”¹è¿›**ï¼šåŸºäºç›‘æ§æ•°æ®æŒç»­ä¼˜åŒ–ç³»ç»Ÿ
    - **å¿«é€Ÿå“åº”**ï¼šå»ºç«‹å¿«é€Ÿçš„æ•…éšœå“åº”æœºåˆ¶
  </guideline>

  <process>
    ## ğŸš€ ç³»ç»Ÿè¿ç»´å·¥ä½œæµç¨‹

    ### è¿ç»´æ¶æ„è®¾è®¡
    ```mermaid
    graph TD
        A[åº”ç”¨å±‚] --> B[æœåŠ¡å±‚]
        B --> C[å¹³å°å±‚]
        C --> D[åŸºç¡€è®¾æ–½å±‚]
        
        A --> A1[PromptXåº”ç”¨]
        A --> A2[MemGPTæœåŠ¡]
        A --> A3[Webç•Œé¢]
        
        B --> B1[APIç½‘å…³]
        B --> B2[è´Ÿè½½å‡è¡¡]
        B --> B3[æœåŠ¡å‘ç°]
        
        C --> C1[å®¹å™¨å¹³å°]
        C --> C2[æ•°æ®åº“]
        C --> C3[ç¼“å­˜ç³»ç»Ÿ]
        C --> C4[æ¶ˆæ¯é˜Ÿåˆ—]
        
        D --> D1[è®¡ç®—èµ„æº]
        D --> D2[å­˜å‚¨èµ„æº]
        D --> D3[ç½‘ç»œèµ„æº]
        D --> D4[å®‰å…¨ç»„ä»¶]
    ```

    ### ç¬¬ä¸€é˜¶æ®µï¼šç¯å¢ƒéƒ¨ç½²ä¸é…ç½®
    ```mermaid
    flowchart TD
        A[ç¯å¢ƒè§„åˆ’] --> B[åŸºç¡€è®¾æ–½å‡†å¤‡]
        B --> C[å¹³å°éƒ¨ç½²]
        C --> D[åº”ç”¨éƒ¨ç½²]
        D --> E[é…ç½®ç®¡ç†]
        E --> F[æµ‹è¯•éªŒè¯]
        
        B --> B1[æœåŠ¡å™¨é…ç½®]
        B --> B2[ç½‘ç»œé…ç½®]
        B --> B3[å®‰å…¨é…ç½®]
        
        C --> C1[Dockeréƒ¨ç½²]
        C --> C2[æ•°æ®åº“éƒ¨ç½²]
        C --> C3[ç›‘æ§éƒ¨ç½²]
        
        D --> D1[åº”ç”¨å®‰è£…]
        D --> D2[ä¾èµ–é…ç½®]
        D --> D3[æœåŠ¡å¯åŠ¨]
        
        E --> E1[ç¯å¢ƒå˜é‡]
        E --> E2[é…ç½®æ–‡ä»¶]
        E --> E3[æƒé™è®¾ç½®]
    ```

    ### ç¬¬äºŒé˜¶æ®µï¼šç›‘æ§ä¸å‘Šè­¦
    ```mermaid
    graph TD
        A[ç›‘æ§ä½“ç³»] --> B[åŸºç¡€ç›‘æ§]
        A --> C[åº”ç”¨ç›‘æ§]
        A --> D[ä¸šåŠ¡ç›‘æ§]
        A --> E[æ—¥å¿—ç›‘æ§]
        
        B --> B1[CPU/å†…å­˜/ç£ç›˜]
        B --> B2[ç½‘ç»œæµé‡]
        B --> B3[ç³»ç»Ÿè¿›ç¨‹]
        
        C --> C1[åº”ç”¨æ€§èƒ½]
        C --> C2[æ¥å£å“åº”]
        C --> C3[é”™è¯¯ç‡]
        
        D --> D1[ç”¨æˆ·è¡Œä¸º]
        D --> D2[ä¸šåŠ¡æŒ‡æ ‡]
        D --> D3[è½¬åŒ–ç‡]
        
        E --> E1[é”™è¯¯æ—¥å¿—]
        E --> E2[è®¿é—®æ—¥å¿—]
        E --> E3[å®¡è®¡æ—¥å¿—]
    ```

    ### ç¬¬ä¸‰é˜¶æ®µï¼šæ•…éšœå¤„ç†ä¸ä¼˜åŒ–
    ```mermaid
    flowchart LR
        A[æ•…éšœå‘ç°] --> B[é—®é¢˜åˆ†æ]
        B --> C[å½±å“è¯„ä¼°]
        C --> D[åº”æ€¥å¤„ç†]
        D --> E[æ ¹å› åˆ†æ]
        E --> F[æ°¸ä¹…ä¿®å¤]
        F --> G[é¢„é˜²æªæ–½]
        
        B --> B1[æ—¥å¿—åˆ†æ]
        B --> B2[ç›‘æ§æ•°æ®]
        B --> B3[ç”¨æˆ·åé¦ˆ]
        
        D --> D1[æœåŠ¡æ¢å¤]
        D --> D2[æµé‡åˆ‡æ¢]
        D --> D3[ä¸´æ—¶æ–¹æ¡ˆ]
        
        E --> E1[ä»£ç åˆ†æ]
        E --> E2[ç¯å¢ƒæ£€æŸ¥]
        E --> E3[é…ç½®å®¡æŸ¥]
    ```

    ## ğŸ› ï¸ PromptXç³»ç»Ÿéƒ¨ç½²å®ç°

    ### Dockerå®¹å™¨åŒ–éƒ¨ç½²
    ```dockerfile
    # PromptXåº”ç”¨Dockerfile
    FROM python:3.11-slim

    WORKDIR /app

    # å®‰è£…ç³»ç»Ÿä¾èµ–
    RUN apt-get update && apt-get install -y \
        gcc \
        g++ \
        && rm -rf /var/lib/apt/lists/*

    # å¤åˆ¶ä¾èµ–æ–‡ä»¶
    COPY requirements.txt .
    RUN pip install --no-cache-dir -r requirements.txt

    # å¤åˆ¶åº”ç”¨ä»£ç 
    COPY . .

    # åˆ›å»ºérootç”¨æˆ·
    RUN useradd -m -u 1000 promptx && chown -R promptx:promptx /app
    USER promptx

    # å¥åº·æ£€æŸ¥
    HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
        CMD python -c "import requests; requests.get('http://localhost:8000/health')"

    EXPOSE 8000

    CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    ```

    ### Docker Composeé…ç½®
    ```yaml
    version: '3.8'

    services:
      promptx-app:
        build: .
        ports:
          - "8000:8000"
        environment:
          - DATABASE_URL=sqlite:///data/promptx.db
          - LOG_LEVEL=INFO
        volumes:
          - ./data:/app/data
          - ./logs:/app/logs
        depends_on:
          - redis
        restart: unless-stopped
        healthcheck:
          test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
          interval: 30s
          timeout: 10s
          retries: 3

      redis:
        image: redis:7-alpine
        ports:
          - "6379:6379"
        volumes:
          - redis_data:/data
        restart: unless-stopped
        healthcheck:
          test: ["CMD", "redis-cli", "ping"]
          interval: 30s
          timeout: 10s
          retries: 3

      prometheus:
        image: prom/prometheus:latest
        ports:
          - "9090:9090"
        volumes:
          - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
          - prometheus_data:/prometheus
        restart: unless-stopped

      grafana:
        image: grafana/grafana:latest
        ports:
          - "3000:3000"
        environment:
          - GF_SECURITY_ADMIN_PASSWORD=admin
        volumes:
          - grafana_data:/var/lib/grafana
          - ./monitoring/grafana:/etc/grafana/provisioning
        restart: unless-stopped

    volumes:
      redis_data:
      prometheus_data:
      grafana_data:
    ```

    ### ç³»ç»Ÿç›‘æ§é…ç½®
    ```python
    import psutil
    import time
    import logging
    from typing import Dict, Any
    from dataclasses import dataclass
    from datetime import datetime

    @dataclass
    class SystemMetrics:
        timestamp: datetime
        cpu_percent: float
        memory_percent: float
        disk_usage: Dict[str, float]
        network_io: Dict[str, int]
        process_count: int

    class SystemMonitor:
        def __init__(self, check_interval: int = 60):
            self.check_interval = check_interval
            self.logger = logging.getLogger(__name__)
            
        def collect_metrics(self) -> SystemMetrics:
            """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # ç£ç›˜ä½¿ç”¨ç‡
            disk_usage = {}
            for partition in psutil.disk_partitions():
                try:
                    usage = psutil.disk_usage(partition.mountpoint)
                    disk_usage[partition.mountpoint] = usage.percent
                except PermissionError:
                    continue
            
            # ç½‘ç»œIO
            network = psutil.net_io_counters()
            network_io = {
                'bytes_sent': network.bytes_sent,
                'bytes_recv': network.bytes_recv,
                'packets_sent': network.packets_sent,
                'packets_recv': network.packets_recv
            }
            
            # è¿›ç¨‹æ•°é‡
            process_count = len(psutil.pids())
            
            return SystemMetrics(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                disk_usage=disk_usage,
                network_io=network_io,
                process_count=process_count
            )
        
        def check_thresholds(self, metrics: SystemMetrics) -> List[str]:
            """æ£€æŸ¥é˜ˆå€¼å‘Šè­¦"""
            alerts = []
            
            # CPUå‘Šè­¦
            if metrics.cpu_percent > 80:
                alerts.append(f"High CPU usage: {metrics.cpu_percent:.1f}%")
            
            # å†…å­˜å‘Šè­¦
            if metrics.memory_percent > 85:
                alerts.append(f"High memory usage: {metrics.memory_percent:.1f}%")
            
            # ç£ç›˜å‘Šè­¦
            for mount, usage in metrics.disk_usage.items():
                if usage > 90:
                    alerts.append(f"High disk usage on {mount}: {usage:.1f}%")
            
            return alerts
        
        def start_monitoring(self):
            """å¯åŠ¨ç›‘æ§"""
            self.logger.info("Starting system monitoring...")
            
            while True:
                try:
                    metrics = self.collect_metrics()
                    alerts = self.check_thresholds(metrics)
                    
                    # è®°å½•æŒ‡æ ‡
                    self.logger.info(f"System metrics: CPU={metrics.cpu_percent:.1f}%, "
                                   f"Memory={metrics.memory_percent:.1f}%, "
                                   f"Processes={metrics.process_count}")
                    
                    # å¤„ç†å‘Šè­¦
                    for alert in alerts:
                        self.logger.warning(f"ALERT: {alert}")
                        self.send_alert(alert)
                    
                    time.sleep(self.check_interval)
                    
                except Exception as e:
                    self.logger.error(f"Monitoring error: {e}")
                    time.sleep(self.check_interval)
        
        def send_alert(self, message: str):
            """å‘é€å‘Šè­¦"""
            # è¿™é‡Œå¯ä»¥é›†æˆé‚®ä»¶ã€çŸ­ä¿¡ã€Slackç­‰å‘Šè­¦æ¸ é“
            print(f"ğŸš¨ ALERT: {message}")
    ```

    ### æ—¥å¿—ç®¡ç†ç³»ç»Ÿ
    ```python
    import logging
    import logging.handlers
    import json
    from datetime import datetime
    from pathlib import Path

    class StructuredLogger:
        def __init__(self, name: str, log_dir: str = "logs"):
            self.name = name
            self.log_dir = Path(log_dir)
            self.log_dir.mkdir(exist_ok=True)
            
            self.logger = logging.getLogger(name)
            self.logger.setLevel(logging.INFO)
            
            # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
            self.logger.handlers.clear()
            
            # æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.handlers.RotatingFileHandler(
                self.log_dir / f"{name}.log",
                maxBytes=10*1024*1024,  # 10MB
                backupCount=5
            )
            
            # JSONæ ¼å¼åŒ–å™¨
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(formatter)
            
            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
        
        def log_structured(self, level: str, message: str, **kwargs):
            """ç»“æ„åŒ–æ—¥å¿—è®°å½•"""
            log_data = {
                'timestamp': datetime.now().isoformat(),
                'level': level,
                'message': message,
                'service': self.name,
                **kwargs
            }
            
            getattr(self.logger, level.lower())(json.dumps(log_data, ensure_ascii=False))
        
        def log_request(self, method: str, path: str, status_code: int, 
                       response_time: float, user_id: str = None):
            """è®°å½•è¯·æ±‚æ—¥å¿—"""
            self.log_structured('info', 'HTTP Request', 
                              method=method, path=path, status_code=status_code,
                              response_time_ms=response_time, user_id=user_id)
        
        def log_error(self, error: Exception, context: Dict[str, Any] = None):
            """è®°å½•é”™è¯¯æ—¥å¿—"""
            self.log_structured('error', str(error),
                              error_type=type(error).__name__,
                              context=context or {})
    ```

    ## ğŸ“Š æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

    ### åº”ç”¨æ€§èƒ½ç›‘æ§
    ```python
    import time
    import functools
    from typing import Callable, Any

    def performance_monitor(func: Callable) -> Callable:
        """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            start_time = time.time()
            
            try:
                result = func(*args, **kwargs)
                execution_time = time.time() - start_time
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                logger = StructuredLogger('performance')
                logger.log_structured('info', 'Function execution',
                                     function=func.__name__,
                                     execution_time_ms=execution_time * 1000,
                                     success=True)
                
                return result
                
            except Exception as e:
                execution_time = time.time() - start_time
                
                # è®°å½•é”™è¯¯å’Œæ€§èƒ½æŒ‡æ ‡
                logger = StructuredLogger('performance')
                logger.log_structured('error', 'Function execution failed',
                                     function=func.__name__,
                                     execution_time_ms=execution_time * 1000,
                                     error=str(e),
                                     success=False)
                raise
        
        return wrapper

    class PerformanceProfiler:
        def __init__(self):
            self.metrics = {}
        
        def profile_function(self, func_name: str, execution_time: float):
            """è®°å½•å‡½æ•°æ€§èƒ½"""
            if func_name not in self.metrics:
                self.metrics[func_name] = {
                    'count': 0,
                    'total_time': 0,
                    'min_time': float('inf'),
                    'max_time': 0
                }
            
            metrics = self.metrics[func_name]
            metrics['count'] += 1
            metrics['total_time'] += execution_time
            metrics['min_time'] = min(metrics['min_time'], execution_time)
            metrics['max_time'] = max(metrics['max_time'], execution_time)
        
        def get_performance_report(self) -> Dict[str, Any]:
            """è·å–æ€§èƒ½æŠ¥å‘Š"""
            report = {}
            
            for func_name, metrics in self.metrics.items():
                avg_time = metrics['total_time'] / metrics['count']
                report[func_name] = {
                    'call_count': metrics['count'],
                    'average_time_ms': avg_time * 1000,
                    'min_time_ms': metrics['min_time'] * 1000,
                    'max_time_ms': metrics['max_time'] * 1000,
                    'total_time_ms': metrics['total_time'] * 1000
                }
            
            return report
    ```

    ## ğŸ”„ è‡ªåŠ¨åŒ–è¿ç»´

    ### éƒ¨ç½²è‡ªåŠ¨åŒ–è„šæœ¬
    ```bash
    #!/bin/bash
    # deploy.sh - PromptXè‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

    set -e

    # é…ç½®å˜é‡
    APP_NAME="promptx"
    DOCKER_IMAGE="promptx:latest"
    BACKUP_DIR="/backup"
    LOG_FILE="/var/log/deploy.log"

    # æ—¥å¿—å‡½æ•°
    log() {
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
    }

    # å¥åº·æ£€æŸ¥
    health_check() {
        local url=$1
        local max_attempts=30
        local attempt=1
        
        while [ $attempt -le $max_attempts ]; do
            if curl -f -s $url > /dev/null; then
                log "Health check passed"
                return 0
            fi
            
            log "Health check attempt $attempt/$max_attempts failed"
            sleep 10
            ((attempt++))
        done
        
        log "Health check failed after $max_attempts attempts"
        return 1
    }

    # å¤‡ä»½å½“å‰ç‰ˆæœ¬
    backup_current() {
        log "Creating backup..."
        
        if docker ps | grep -q $APP_NAME; then
            docker commit $APP_NAME $APP_NAME:backup-$(date +%Y%m%d-%H%M%S)
            log "Backup created successfully"
        else
            log "No running container to backup"
        fi
    }

    # éƒ¨ç½²æ–°ç‰ˆæœ¬
    deploy() {
        log "Starting deployment..."
        
        # åœæ­¢æ—§å®¹å™¨
        if docker ps | grep -q $APP_NAME; then
            log "Stopping old container..."
            docker stop $APP_NAME
            docker rm $APP_NAME
        fi
        
        # å¯åŠ¨æ–°å®¹å™¨
        log "Starting new container..."
        docker run -d \
            --name $APP_NAME \
            --restart unless-stopped \
            -p 8000:8000 \
            -v $(pwd)/data:/app/data \
            -v $(pwd)/logs:/app/logs \
            $DOCKER_IMAGE
        
        # å¥åº·æ£€æŸ¥
        if health_check "http://localhost:8000/health"; then
            log "Deployment successful"
            return 0
        else
            log "Deployment failed, rolling back..."
            rollback
            return 1
        fi
    }

    # å›æ»š
    rollback() {
        log "Rolling back to previous version..."
        
        # åœæ­¢å¤±è´¥çš„å®¹å™¨
        docker stop $APP_NAME || true
        docker rm $APP_NAME || true
        
        # å¯åŠ¨å¤‡ä»½ç‰ˆæœ¬
        local backup_image=$(docker images | grep "$APP_NAME:backup" | head -1 | awk '{print $1":"$2}')
        if [ -n "$backup_image" ]; then
            docker run -d \
                --name $APP_NAME \
                --restart unless-stopped \
                -p 8000:8000 \
                -v $(pwd)/data:/app/data \
                -v $(pwd)/logs:/app/logs \
                $backup_image
            
            log "Rollback completed"
        else
            log "No backup image found for rollback"
        fi
    }

    # ä¸»æµç¨‹
    main() {
        log "Starting deployment process..."
        
        backup_current
        
        if deploy; then
            log "Deployment completed successfully"
            exit 0
        else
            log "Deployment failed"
            exit 1
        fi
    }

    main "$@"
    ```
  </process>

  <criteria>
    ## ç³»ç»Ÿè¿ç»´è¯„ä»·æ ‡å‡†

    ### å¯ç”¨æ€§æŒ‡æ ‡
    - âœ… ç³»ç»Ÿå¯ç”¨æ€§ â‰¥ 99.5%
    - âœ… å¹³å‡æ•…éšœæ¢å¤æ—¶é—´ â‰¤ 30åˆ†é’Ÿ
    - âœ… è®¡åˆ’å†…åœæœºæ—¶é—´ â‰¤ 4å°æ—¶/æœˆ
    - âœ… æ•°æ®ä¸¢å¤±ç‡ = 0%

    ### æ€§èƒ½æŒ‡æ ‡
    - âœ… ç³»ç»Ÿå“åº”æ—¶é—´ â‰¤ 2ç§’
    - âœ… å¹¶å‘ç”¨æˆ·æ”¯æŒ â‰¥ 1000
    - âœ… èµ„æºåˆ©ç”¨ç‡ â‰¤ 80%
    - âœ… æ‰©å±•æ€§è‰¯å¥½

    ### å®‰å…¨æŒ‡æ ‡
    - âœ… å®‰å…¨äº‹ä»¶å“åº”æ—¶é—´ â‰¤ 1å°æ—¶
    - âœ… è®¿é—®æ§åˆ¶æœ‰æ•ˆæ€§ 100%
    - âœ… æ•°æ®å¤‡ä»½å®Œæ•´æ€§ 100%
    - âœ… åˆè§„æ€§æ£€æŸ¥é€šè¿‡ç‡ 100%

    ### è¿ç»´æ•ˆç‡
    - âœ… è‡ªåŠ¨åŒ–ç¨‹åº¦ â‰¥ 80%
    - âœ… ç›‘æ§è¦†ç›–ç‡ â‰¥ 95%
    - âœ… å‘Šè­¦å‡†ç¡®ç‡ â‰¥ 90%
    - âœ… æ–‡æ¡£å®Œæ•´æ€§ â‰¥ 95%
  </criteria>
</execution>
